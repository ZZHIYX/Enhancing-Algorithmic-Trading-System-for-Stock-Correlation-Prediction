{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "import joblib\n",
    "sys.modules['sklearn.externals.joblib'] = joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scipy.stats as stats\n",
    "import pylab as pl\n",
    "from pyramid.arima import ARIMA, auto_arima\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price_df = pd.read_csv(\"./20industries_ETF_prc_UNSTACKED.csv\")\n",
    "portfolio = stock_price_df.columns[1:]\n",
    "stock_num = len(portfolio) # exclude datadate\n",
    "window_len = 100\n",
    "dp_num = stock_price_df.shape[0]\n",
    "corr_num = dp_num - window_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_returns(r_df):\n",
    "    mean_r = r_df.mean(axis=0)\n",
    "    sd_r = r_df.std(axis=0)\n",
    "    normed_df = (r_df - mean_r) /sd_r\n",
    "    return normed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rolling_corr(item1,item2):\n",
    "    #import data\n",
    "    stock_price_df = pd.read_csv(\"./20industries_ETF_prc_UNSTACKED.csv\")\n",
    "    pd.to_datetime(stock_price_df['datadate'], format='%Y-%m-%d')\n",
    "    stock_price_df = stock_price_df.set_index(pd.DatetimeIndex(stock_price_df['datadate']))\n",
    "    \n",
    "    #calculate\n",
    "    df_pair = pd.concat([stock_price_df[item1], stock_price_df[item2]], axis=1)\n",
    "    df_pair.columns = [item1,item2]\n",
    "    df_pair = normalize_returns(df_pair)\n",
    "    df_pair = df_pair.ewm(halflife=100/12).mean()\n",
    "    df_corr = df_pair[item1].rolling(window=window_len).corr(df_pair[item2])\n",
    "    return df_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for _ in range(window_len):\n",
    "    indices = []\n",
    "    for k in range(_, corr_num,window_len):\n",
    "        indices.append(k)\n",
    "    index_list.append(indices)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 19\n",
      "0 18\n",
      "0 17\n",
      "0 16\n",
      "0 15\n",
      "0 14\n",
      "0 13\n",
      "0 12\n",
      "0 11\n",
      "0 10\n",
      "0 9\n",
      "0 8\n",
      "0 7\n",
      "0 6\n",
      "0 5\n",
      "0 4\n",
      "0 3\n",
      "0 2\n",
      "0 1\n",
      "1 19\n",
      "1 18\n",
      "1 17\n",
      "1 16\n",
      "1 15\n",
      "1 14\n",
      "1 13\n",
      "1 12\n",
      "1 11\n",
      "1 10\n",
      "1 9\n",
      "1 8\n",
      "1 7\n",
      "1 6\n",
      "1 5\n",
      "1 4\n",
      "1 3\n",
      "1 2\n",
      "2 19\n",
      "2 18\n",
      "2 17\n",
      "2 16\n",
      "2 15\n",
      "2 14\n",
      "2 13\n",
      "2 12\n",
      "2 11\n",
      "2 10\n",
      "2 9\n",
      "2 8\n",
      "2 7\n",
      "2 6\n",
      "2 5\n",
      "2 4\n",
      "2 3\n",
      "3 19\n",
      "3 18\n",
      "3 17\n",
      "3 16\n",
      "3 15\n",
      "3 14\n",
      "3 13\n",
      "3 12\n",
      "3 11\n",
      "3 10\n",
      "3 9\n",
      "3 8\n",
      "3 7\n",
      "3 6\n",
      "3 5\n",
      "3 4\n",
      "4 19\n",
      "4 18\n",
      "4 17\n",
      "4 16\n",
      "4 15\n",
      "4 14\n",
      "4 13\n",
      "4 12\n",
      "4 11\n",
      "4 10\n",
      "4 9\n",
      "4 8\n",
      "4 7\n",
      "4 6\n",
      "4 5\n",
      "5 19\n",
      "5 18\n",
      "5 17\n",
      "5 16\n",
      "5 15\n",
      "5 14\n",
      "5 13\n",
      "5 12\n",
      "5 11\n",
      "5 10\n",
      "5 9\n",
      "5 8\n",
      "5 7\n",
      "5 6\n",
      "6 19\n",
      "6 18\n",
      "6 17\n",
      "6 16\n",
      "6 15\n",
      "6 14\n",
      "6 13\n",
      "6 12\n",
      "6 11\n",
      "6 10\n",
      "6 9\n",
      "6 8\n",
      "6 7\n",
      "7 19\n",
      "7 18\n",
      "7 17\n",
      "7 16\n",
      "7 15\n",
      "7 14\n",
      "7 13\n",
      "7 12\n",
      "7 11\n",
      "7 10\n",
      "7 9\n",
      "7 8\n",
      "8 19\n",
      "8 18\n",
      "8 17\n",
      "8 16\n",
      "8 15\n",
      "8 14\n",
      "8 13\n",
      "8 12\n",
      "8 11\n",
      "8 10\n",
      "8 9\n",
      "9 19\n",
      "9 18\n",
      "9 17\n",
      "9 16\n",
      "9 15\n",
      "9 14\n",
      "9 13\n",
      "9 12\n",
      "9 11\n",
      "9 10\n",
      "10 19\n",
      "10 18\n",
      "10 17\n",
      "10 16\n",
      "10 15\n",
      "10 14\n",
      "10 13\n",
      "10 12\n",
      "10 11\n",
      "11 19\n",
      "11 18\n",
      "11 17\n",
      "11 16\n",
      "11 15\n",
      "11 14\n",
      "11 13\n",
      "11 12\n",
      "12 19\n",
      "12 18\n",
      "12 17\n",
      "12 16\n",
      "12 15\n",
      "12 14\n",
      "12 13\n",
      "13 19\n",
      "13 18\n",
      "13 17\n",
      "13 16\n",
      "13 15\n",
      "13 14\n",
      "14 19\n",
      "14 18\n",
      "14 17\n",
      "14 16\n",
      "14 15\n",
      "15 19\n",
      "15 18\n",
      "15 17\n",
      "15 16\n",
      "16 19\n",
      "16 18\n",
      "16 17\n",
      "17 19\n",
      "17 18\n",
      "18 19\n"
     ]
    }
   ],
   "source": [
    "data_matrix = []\n",
    "count = 0\n",
    "for i in range(stock_num):\n",
    "    for j in range(stock_num - 1 -i):\n",
    "        a = portfolio[i]\n",
    "        b = portfolio[stock_num-1-j]\n",
    "        print(i, stock_num-1-j)\n",
    "        corr_series = rolling_corr(a, b)[window_len-1:]\n",
    "\n",
    "        for _ in range(100):\n",
    "            tmp = corr_series[index_list[_]]\n",
    "            corr_strided = list(tmp[:corr_num//window_len]).copy()\n",
    "            data_matrix.append(corr_strided)\n",
    "            count+=1\n",
    "            # if count % 1000 == 0 :\n",
    "            #     print(str(count)+' items preprocessed')\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix = np.transpose(data_matrix)\n",
    "data_dictionary = {}\n",
    "for i in range(len(data_matrix)):\n",
    "    data_dictionary[str(i)] = data_matrix[i]\n",
    "data_df = pd.DataFrame(data_dictionary)\n",
    "data_df.to_csv('./dataset.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19000, 31)\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv('./dataset.csv')\n",
    "data_df = data_df.loc[:, ~data_df.columns.str.contains('^Unnamed')]\n",
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19000, 31)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape1=data_df.shape[1]\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 19000)\n",
      "      0         1         2         3         4         5         6      \\\n",
      "0  0.735596  0.760432  0.782987  0.802947  0.821891  0.840724  0.859620   \n",
      "1  0.336218  0.362861  0.389192  0.416113  0.444440  0.472311  0.499678   \n",
      "2  0.959626  0.960538  0.961495  0.962518  0.963556  0.964589  0.965583   \n",
      "3  0.974181  0.973509  0.972590  0.971102  0.969305  0.967385  0.965260   \n",
      "4  0.998502  0.998471  0.998433  0.998382  0.998315  0.998244  0.998168   \n",
      "\n",
      "      7         8         9      ...     18990     18991     18992     18993  \\\n",
      "0  0.877712  0.894373  0.909033  ...  0.117876  0.106967  0.098010  0.091929   \n",
      "1  0.527696  0.555833  0.583913  ...  0.831777  0.833079  0.833626  0.833399   \n",
      "2  0.966540  0.967483  0.968398  ...  0.742016  0.727992  0.713514  0.698542   \n",
      "3  0.963071  0.960832  0.958517  ...  0.990574  0.991235  0.991872  0.992484   \n",
      "4  0.998084  0.997995  0.997906  ...  0.652544  0.696987  0.735088  0.767546   \n",
      "\n",
      "      18994     18995     18996     18997     18998     18999  \n",
      "0  0.089999  0.094539  0.104725  0.121852  0.143573  0.166879  \n",
      "1  0.832602  0.830663  0.827855  0.824542  0.821266  0.817415  \n",
      "2  0.684005  0.669452  0.655443  0.641191  0.626246  0.611156  \n",
      "3  0.993030  0.993542  0.993967  0.994365  0.994737  0.995092  \n",
      "4  0.794782  0.817037  0.834529  0.848685  0.860246  0.869674  \n",
      "\n",
      "[5 rows x 19000 columns]\n"
     ]
    }
   ],
   "source": [
    "num_list = []\n",
    "for i in range(31):\n",
    "    num_list.append(str(i))\n",
    "data_df = data_df[num_list].copy()\n",
    "data_df = np.transpose(data_df)\n",
    "print(data_df.shape)\n",
    "print(data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [20*k for k in range(950)]\n",
    "data_df = pd.DataFrame(data_df[indices])\n",
    "\n",
    "train = []\n",
    "dev = []\n",
    "test1 = []\n",
    "test2 = []\n",
    "\n",
    "for i in range(data_df.shape[1]):\n",
    "    tmp = data_df[20*i].copy()\n",
    "    train.append(tmp[:(shape1-10)]) # 0:21  （0：20；  21）\n",
    "    dev.append(tmp[3:(shape1-7)]) # 3：24   （    ；    ）\n",
    "    test1.append(tmp[6:(shape1-3)]) # 6：27\n",
    "    test2.append(tmp[10:shape1]) # 10：31\n",
    "\n",
    "train = pd.DataFrame(train)\n",
    "dev = pd.DataFrame(dev)\n",
    "test1 = pd.DataFrame(test1)\n",
    "test2 = pd.DataFrame(test2)\n",
    "\n",
    "train.to_csv('./my_data/train_dev_test/before_arima/train.csv')\n",
    "dev.to_csv('./my_data/train_dev_test/before_arima/dev.csv')\n",
    "test1.to_csv('./my_data/train_dev_test/before_arima/test1.csv')\n",
    "test2.to_csv('./my_data/train_dev_test/before_arima/test2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./my_data/train_dev_test/before_arima/train.csv')\n",
    "dev = pd.read_csv('./my_data/train_dev_test/before_arima/dev.csv')\n",
    "test1 = pd.read_csv('./my_data/train_dev_test/before_arima/test1.csv')\n",
    "test2 = pd.read_csv('./my_data/train_dev_test/before_arima/test2.csv')\n",
    "\n",
    "train = np.transpose(train.loc[:,~train.columns.str.contains('^Unnamed')])\n",
    "dev = np.transpose(dev.loc[:,~dev.columns.str.contains('^Unnamed')])\n",
    "test1 = np.transpose(test1.loc[:,~test1.columns.str.contains('^Unnamed')])\n",
    "test2 = np.transpose(test2.loc[:,~test2.columns.str.contains('^Unnamed')])\n",
    "\n",
    "datasets = [train, dev, test1, test2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 950)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n"
     ]
    }
   ],
   "source": [
    "model_110 = ARIMA(order=(1,1,0), method='mle', suppress_warnings=True)\n",
    "model_011 = ARIMA(order=(0,1,1), method='mle', suppress_warnings=True)\n",
    "model_111 = ARIMA(order=(1,1,1), method='mle', suppress_warnings=True)\n",
    "model_211 = ARIMA(order=(2,1,1), method='mle', suppress_warnings=True)\n",
    "model_210 = ARIMA(order=(2,1,0), method='mle', suppress_warnings=True)\n",
    "\n",
    "train_X = []; train_Y = []\n",
    "dev_X = []; dev_Y = []\n",
    "test1_X = []; test1_Y = []\n",
    "test2_X = []; test2_Y = []\n",
    "\n",
    "flag = 0\n",
    "\n",
    "prediction_21st = []\n",
    "\n",
    "for i in range(950):\n",
    "    print(i)\n",
    "    tmp = []\n",
    "    c=0\n",
    "    for s in datasets :\n",
    "        c+=1\n",
    "        try:\n",
    "            model1 = model_110.fit(s[i])\n",
    "            model = model1\n",
    "            \n",
    "            try:\n",
    "                model2 = model_011.fit(s[i])\n",
    "                \n",
    "                if model.aic() <= model2.aic() :\n",
    "                    pass\n",
    "                else :\n",
    "                    model = model2\n",
    "                    \n",
    "                try :\n",
    "                    model3 = model_111.fit(s[i])\n",
    "                    if model.aic() <= model3.aic() :\n",
    "                        pass\n",
    "                    else :\n",
    "                        model = model3\n",
    "                except :\n",
    "                    try:\n",
    "                        model4 = model_211.fit(s[i])\n",
    "                        \n",
    "                        if model.aic() <= model4.aic() :\n",
    "                            pass\n",
    "                        else:\n",
    "                            model = model4\n",
    "                    except:\n",
    "                        try:\n",
    "                            model5 = model_210.fit(s[i])\n",
    "                            \n",
    "                            if model.aic() <= model5.aic():\n",
    "                                pass\n",
    "                            else :\n",
    "                                model = model5\n",
    "                        except :\n",
    "                            pass\n",
    "                    \n",
    "            except:\n",
    "                try:\n",
    "                    model3 = model_111.fit(s[i])\n",
    "\n",
    "                    if model.aic() <= model3.aic() :\n",
    "                        pass\n",
    "                    else :\n",
    "                        model = model3\n",
    "                except :\n",
    "                    try:\n",
    "                        model4 = model_211.fit(s[i])\n",
    "                        \n",
    "                        if model.aic() <= model4.aic() :\n",
    "                            pass\n",
    "                        else:\n",
    "                            model = model4\n",
    "                    except:\n",
    "                        try:\n",
    "                            model5 = model_210.fit(s[i])\n",
    "                            \n",
    "                            if model.aic() <= model5.aic():\n",
    "                                pass\n",
    "                            else :\n",
    "                                model = model5\n",
    "                        except :\n",
    "                            pass\n",
    "                \n",
    "        except:\n",
    "            try:\n",
    "                model2 = model_011.fit(s[i])\n",
    "                model = model2\n",
    "            \n",
    "                try :\n",
    "                    model3 = model_111.fit(s[i])\n",
    "                    \n",
    "                    if model.aic() <= model3.aic():\n",
    "                        pass\n",
    "                    else:\n",
    "                        model = model3\n",
    "                except :\n",
    "                    try:\n",
    "                        model4 = model_211.fit(s[i])\n",
    "                        \n",
    "                        if model.aic() <= model4.aic() :\n",
    "                            pass\n",
    "                        else:\n",
    "                            model = model4\n",
    "                    except:\n",
    "                        try:\n",
    "                            model5 = model_210.fit(s[i])\n",
    "                            \n",
    "                            if model.aic() <= model5.aic():\n",
    "                                pass\n",
    "                            else :\n",
    "                                model = model5\n",
    "                        except :\n",
    "                            pass\n",
    "            \n",
    "            except :\n",
    "                try:\n",
    "                    model3 = model_111.fit(s[i])\n",
    "                    model = model3\n",
    "                except :\n",
    "                    try:\n",
    "                        model4 = model_211.fit(s[i])\n",
    "                        \n",
    "                        if model.aic() <= model4.aic() :\n",
    "                            pass\n",
    "                        else:\n",
    "                            model = model4\n",
    "                    except:\n",
    "                        try:\n",
    "                            model5 = model_210.fit(s[i])\n",
    "                            \n",
    "                            if model.aic() <= model5.aic():\n",
    "                                pass\n",
    "                            else :\n",
    "                                model = model5\n",
    "                        except :\n",
    "                            flag = 1\n",
    "                            print(str(c) + \" FATAL ERROR\")\n",
    "                            break\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        predictions = list(model.predict_in_sample())\n",
    "        #pad the first time step of predictions with the average of the prediction values\n",
    "        #so as to match the length of the s[i] data\n",
    "        predictions = [np.mean(predictions)] + predictions # [21]   * 950 iterations\n",
    "        \n",
    "        prediction_21st.append(predictions[-1])\n",
    "        \n",
    "        residual = pd.Series(np.array(s[i]) - np.array(predictions))\n",
    "        tmp.append(np.array(residual))\n",
    "\n",
    "\n",
    "    if flag == 1:\n",
    "        break\n",
    "    train_X.append(tmp[0][:20])\n",
    "    train_Y.append(tmp[0][20])\n",
    "    dev_X.append(tmp[1][:20])\n",
    "    dev_Y.append(tmp[1][20])\n",
    "    test1_X.append(tmp[2][:20])\n",
    "    test1_Y.append(tmp[2][20])\n",
    "    test2_X.append(tmp[3][:20])\n",
    "    test2_Y.append(tmp[3][20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05670299, -0.31477943, -0.25891605, ..., -0.61862703,\n",
       "       -0.91171716, -0.27668108])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_21st = np.array(prediction_21st)\n",
    "prediction_21st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train_X).to_csv('./my_data/train_dev_test/after_arima/train_X.csv')\n",
    "pd.DataFrame(dev_X).to_csv('./my_data/train_dev_test/after_arima/dev_X.csv')\n",
    "pd.DataFrame(test1_X).to_csv('./my_data/train_dev_test/after_arima/test1_X.csv')\n",
    "pd.DataFrame(test2_X).to_csv('./my_data/train_dev_test/after_arima/test2_X.csv')\n",
    "pd.DataFrame(train_Y).to_csv('./my_data/train_dev_test/after_arima/train_Y.csv')\n",
    "pd.DataFrame(dev_Y).to_csv('./my_data/train_dev_test/after_arima/dev_Y.csv')\n",
    "pd.DataFrame(test1_Y).to_csv('./my_data/train_dev_test/after_arima/test1_Y.csv')\n",
    "pd.DataFrame(test2_Y).to_csv('./my_data/train_dev_test/after_arima/test2_Y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007158836689038032 % of the data is out of bound [-2,2]\n",
      "0.6030425055928411 % of the data is out of bound [-1,1]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./my_data/train_dev_test/after_arima/train_X.csv')\n",
    "train = np.transpose(train.loc[:,~train.columns.str.contains('^Unnamed')])\n",
    "train_melt = sorted(np.array(train.melt()['value']))\n",
    "fit = stats.norm.pdf(train_melt, np.mean(train_melt), np.std(train_melt))\n",
    "pl.hist(train_melt,density=True, color='grey', bins=[-4,-3,-2,-1,0,1,2,3,4,5])\n",
    "pl.plot(train_melt,fit,color='blue')\n",
    "pl.title('residual value distribution')\n",
    "pl.xlabel('residual')\n",
    "pl.show()\n",
    "pl.close()\n",
    "\n",
    "X = [x for x in train_melt if x>2]\n",
    "Y = [y for y in train_melt if y<-2]\n",
    "out_of_bound = X + Y\n",
    "print(str(len(out_of_bound)/11175) +' % of the data is out of bound [-2,2]')\n",
    "\n",
    "X = [x for x in train_melt if x>1]\n",
    "Y = [y for y in train_melt if y<-1]\n",
    "out_of_bound = X + Y\n",
    "print(str(len(out_of_bound)/11175) +' % of the data is out of bound [-1,1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.857608</td>\n",
       "      <td>0.809016</td>\n",
       "      <td>0.809820</td>\n",
       "      <td>0.840703</td>\n",
       "      <td>0.891375</td>\n",
       "      <td>0.806982</td>\n",
       "      <td>0.753754</td>\n",
       "      <td>0.765899</td>\n",
       "      <td>0.706988</td>\n",
       "      <td>0.721054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643922</td>\n",
       "      <td>0.650732</td>\n",
       "      <td>0.673487</td>\n",
       "      <td>0.675382</td>\n",
       "      <td>0.687721</td>\n",
       "      <td>0.629792</td>\n",
       "      <td>0.611499</td>\n",
       "      <td>0.672020</td>\n",
       "      <td>0.739272</td>\n",
       "      <td>0.733342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.415463</td>\n",
       "      <td>0.399509</td>\n",
       "      <td>0.360067</td>\n",
       "      <td>0.283767</td>\n",
       "      <td>0.450546</td>\n",
       "      <td>0.403639</td>\n",
       "      <td>0.521517</td>\n",
       "      <td>0.438191</td>\n",
       "      <td>0.634323</td>\n",
       "      <td>0.587508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575976</td>\n",
       "      <td>0.616642</td>\n",
       "      <td>0.485369</td>\n",
       "      <td>0.449595</td>\n",
       "      <td>0.681552</td>\n",
       "      <td>0.632418</td>\n",
       "      <td>0.660497</td>\n",
       "      <td>0.484928</td>\n",
       "      <td>0.287431</td>\n",
       "      <td>0.386691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.182239</td>\n",
       "      <td>0.065283</td>\n",
       "      <td>0.100846</td>\n",
       "      <td>0.153408</td>\n",
       "      <td>-0.400931</td>\n",
       "      <td>-0.261993</td>\n",
       "      <td>-0.220308</td>\n",
       "      <td>-0.426096</td>\n",
       "      <td>-1.234267</td>\n",
       "      <td>-1.254576</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.569621</td>\n",
       "      <td>-0.758729</td>\n",
       "      <td>-0.661587</td>\n",
       "      <td>-0.508081</td>\n",
       "      <td>-1.176764</td>\n",
       "      <td>-0.668579</td>\n",
       "      <td>-0.586123</td>\n",
       "      <td>-0.755698</td>\n",
       "      <td>0.186525</td>\n",
       "      <td>-0.072571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.741909</td>\n",
       "      <td>0.521882</td>\n",
       "      <td>0.481639</td>\n",
       "      <td>0.677451</td>\n",
       "      <td>0.972234</td>\n",
       "      <td>0.655024</td>\n",
       "      <td>0.498473</td>\n",
       "      <td>0.517681</td>\n",
       "      <td>0.605701</td>\n",
       "      <td>0.578950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280808</td>\n",
       "      <td>0.621491</td>\n",
       "      <td>0.569162</td>\n",
       "      <td>0.341092</td>\n",
       "      <td>0.257886</td>\n",
       "      <td>0.357634</td>\n",
       "      <td>0.088013</td>\n",
       "      <td>0.568959</td>\n",
       "      <td>0.565151</td>\n",
       "      <td>0.512879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.074934</td>\n",
       "      <td>0.992658</td>\n",
       "      <td>0.985519</td>\n",
       "      <td>0.922792</td>\n",
       "      <td>1.006067</td>\n",
       "      <td>0.869793</td>\n",
       "      <td>0.865296</td>\n",
       "      <td>0.886864</td>\n",
       "      <td>0.937599</td>\n",
       "      <td>0.888179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956699</td>\n",
       "      <td>0.764753</td>\n",
       "      <td>0.682364</td>\n",
       "      <td>0.740769</td>\n",
       "      <td>0.921185</td>\n",
       "      <td>0.817256</td>\n",
       "      <td>0.910160</td>\n",
       "      <td>0.801487</td>\n",
       "      <td>0.791668</td>\n",
       "      <td>0.813032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.137954</td>\n",
       "      <td>1.086591</td>\n",
       "      <td>1.034051</td>\n",
       "      <td>0.991195</td>\n",
       "      <td>1.050990</td>\n",
       "      <td>1.043857</td>\n",
       "      <td>0.990546</td>\n",
       "      <td>1.076174</td>\n",
       "      <td>1.059541</td>\n",
       "      <td>1.031162</td>\n",
       "      <td>...</td>\n",
       "      <td>1.073093</td>\n",
       "      <td>1.073488</td>\n",
       "      <td>0.939227</td>\n",
       "      <td>1.058164</td>\n",
       "      <td>1.175713</td>\n",
       "      <td>1.145514</td>\n",
       "      <td>1.149919</td>\n",
       "      <td>0.981363</td>\n",
       "      <td>0.968504</td>\n",
       "      <td>1.063408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.271372</td>\n",
       "      <td>1.256426</td>\n",
       "      <td>1.197243</td>\n",
       "      <td>1.279478</td>\n",
       "      <td>1.450451</td>\n",
       "      <td>1.309549</td>\n",
       "      <td>1.693783</td>\n",
       "      <td>1.281826</td>\n",
       "      <td>1.335333</td>\n",
       "      <td>1.419444</td>\n",
       "      <td>...</td>\n",
       "      <td>1.229897</td>\n",
       "      <td>1.267617</td>\n",
       "      <td>1.294056</td>\n",
       "      <td>1.229933</td>\n",
       "      <td>1.277378</td>\n",
       "      <td>1.327378</td>\n",
       "      <td>1.262594</td>\n",
       "      <td>1.175528</td>\n",
       "      <td>1.070674</td>\n",
       "      <td>1.199846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2          3          4          5    \\\n",
       "count  20.000000  20.000000  20.000000  20.000000  20.000000  20.000000   \n",
       "mean    0.857608   0.809016   0.809820   0.840703   0.891375   0.806982   \n",
       "std     0.415463   0.399509   0.360067   0.283767   0.450546   0.403639   \n",
       "min    -0.182239   0.065283   0.100846   0.153408  -0.400931  -0.261993   \n",
       "25%     0.741909   0.521882   0.481639   0.677451   0.972234   0.655024   \n",
       "50%     1.074934   0.992658   0.985519   0.922792   1.006067   0.869793   \n",
       "75%     1.137954   1.086591   1.034051   0.991195   1.050990   1.043857   \n",
       "max     1.271372   1.256426   1.197243   1.279478   1.450451   1.309549   \n",
       "\n",
       "             6          7          8          9    ...        180        181  \\\n",
       "count  20.000000  20.000000  20.000000  20.000000  ...  20.000000  20.000000   \n",
       "mean    0.753754   0.765899   0.706988   0.721054  ...   0.643922   0.650732   \n",
       "std     0.521517   0.438191   0.634323   0.587508  ...   0.575976   0.616642   \n",
       "min    -0.220308  -0.426096  -1.234267  -1.254576  ...  -0.569621  -0.758729   \n",
       "25%     0.498473   0.517681   0.605701   0.578950  ...   0.280808   0.621491   \n",
       "50%     0.865296   0.886864   0.937599   0.888179  ...   0.956699   0.764753   \n",
       "75%     0.990546   1.076174   1.059541   1.031162  ...   1.073093   1.073488   \n",
       "max     1.693783   1.281826   1.335333   1.419444  ...   1.229897   1.267617   \n",
       "\n",
       "             182        183        184        185        186        187  \\\n",
       "count  20.000000  20.000000  20.000000  20.000000  20.000000  20.000000   \n",
       "mean    0.673487   0.675382   0.687721   0.629792   0.611499   0.672020   \n",
       "std     0.485369   0.449595   0.681552   0.632418   0.660497   0.484928   \n",
       "min    -0.661587  -0.508081  -1.176764  -0.668579  -0.586123  -0.755698   \n",
       "25%     0.569162   0.341092   0.257886   0.357634   0.088013   0.568959   \n",
       "50%     0.682364   0.740769   0.921185   0.817256   0.910160   0.801487   \n",
       "75%     0.939227   1.058164   1.175713   1.145514   1.149919   0.981363   \n",
       "max     1.294056   1.229933   1.277378   1.327378   1.262594   1.175528   \n",
       "\n",
       "             188        189  \n",
       "count  20.000000  20.000000  \n",
       "mean    0.739272   0.733342  \n",
       "std     0.287431   0.386691  \n",
       "min     0.186525  -0.072571  \n",
       "25%     0.565151   0.512879  \n",
       "50%     0.791668   0.813032  \n",
       "75%     0.968504   1.063408  \n",
       "max     1.070674   1.199846  \n",
       "\n",
       "[8 rows x 190 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat = pd.DataFrame()\n",
    "for i in range(190):\n",
    "    df = train[i].describe()\n",
    "    stat[i] = df\n",
    "stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded train_X\n",
      "loaded dev_X\n",
      "loaded test1_X\n",
      "loaded test2_X\n",
      "loaded train_Y\n",
      "loaded dev_Y\n",
      "loaded test1_Y\n",
      "loaded test2_Y\n",
      "[]\n",
      "2/2 [==============================] - 1s 12ms/step - loss: 0.2635 - mse: 0.2635 - mae: 0.4127\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch263.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2633 - mse: 0.2633 - mae: 0.4166\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2237 - mse: 0.2237 - mae: 0.3904\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3061 - mse: 0.3061 - mae: 0.4513\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3116 - mse: 0.3116 - mae: 0.4779\n",
      "train set score : mse - 0.26328474283218384 / mae - 0.4165594279766083\n",
      "dev set score : mse - 0.22368231415748596 / mae - 0.3904370069503784\n",
      "test1 set score : mse - 0.3061307668685913 / mae - 0.45125630497932434\n",
      "test2 set score : mse - 0.31161633133888245 / mae - 0.47793981432914734\n",
      "2/2 [==============================] - 1s 12ms/step - loss: 0.2637 - mse: 0.2637 - mae: 0.4124\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch264.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2630 - mse: 0.2630 - mae: 0.4061\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2058 - mse: 0.2058 - mae: 0.3688\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3101 - mse: 0.3101 - mae: 0.4495\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3017 - mse: 0.3017 - mae: 0.4643\n",
      "train set score : mse - 0.2630104720592499 / mae - 0.4060969054698944\n",
      "dev set score : mse - 0.2057887315750122 / mae - 0.3687567412853241\n",
      "test1 set score : mse - 0.31006959080696106 / mae - 0.4494701623916626\n",
      "test2 set score : mse - 0.3016640841960907 / mae - 0.4642503261566162\n",
      "2/2 [==============================] - 1s 11ms/step - loss: 0.2625 - mse: 0.2625 - mae: 0.4083\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch265.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2635 - mse: 0.2635 - mae: 0.4187\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2282 - mse: 0.2282 - mae: 0.3957\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3050 - mse: 0.3050 - mae: 0.4515\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3149 - mse: 0.3149 - mae: 0.4818\n",
      "train set score : mse - 0.26347994804382324 / mae - 0.4186854958534241\n",
      "dev set score : mse - 0.22824865579605103 / mae - 0.39566749334335327\n",
      "test1 set score : mse - 0.30503925681114197 / mae - 0.45153695344924927\n",
      "test2 set score : mse - 0.31488481163978577 / mae - 0.4818376898765564\n",
      "2/2 [==============================] - 1s 17ms/step - loss: 0.2628 - mse: 0.2628 - mae: 0.4162\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch266.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2637 - mse: 0.2637 - mae: 0.4025\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1999 - mse: 0.1999 - mae: 0.3617\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3123 - mse: 0.3123 - mae: 0.4494\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2978 - mse: 0.2978 - mae: 0.4590\n",
      "train set score : mse - 0.26368001103401184 / mae - 0.40254461765289307\n",
      "dev set score : mse - 0.19994547963142395 / mae - 0.36173999309539795\n",
      "test1 set score : mse - 0.3123377859592438 / mae - 0.4493813216686249\n",
      "test2 set score : mse - 0.2977881133556366 / mae - 0.45895642042160034\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x000001E70B0A2510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 14ms/step - loss: 0.2638 - mse: 0.2638 - mae: 0.4072\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch267.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2617 - mse: 0.2617 - mae: 0.4111\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2153 - mse: 0.2153 - mae: 0.3808\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3065 - mse: 0.3065 - mae: 0.4496\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3065 - mse: 0.3065 - mae: 0.4719\n",
      "train set score : mse - 0.2617419362068176 / mae - 0.41114306449890137\n",
      "dev set score : mse - 0.2152707725763321 / mae - 0.3808112144470215\n",
      "test1 set score : mse - 0.3064593970775604 / mae - 0.44962820410728455\n",
      "test2 set score : mse - 0.30653008818626404 / mae - 0.47186657786369324\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x000001E70B20CD90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 11ms/step - loss: 0.2617 - mse: 0.2617 - mae: 0.4109\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch268.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2616 - mse: 0.2616 - mae: 0.4080\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2098 - mse: 0.2098 - mae: 0.3743\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3076 - mse: 0.3076 - mae: 0.4491\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3031 - mse: 0.3031 - mae: 0.4674\n",
      "train set score : mse - 0.261588990688324 / mae - 0.4080013036727905\n",
      "dev set score : mse - 0.20984935760498047 / mae - 0.374279648065567\n",
      "test1 set score : mse - 0.30761802196502686 / mae - 0.44913262128829956\n",
      "test2 set score : mse - 0.3031373918056488 / mae - 0.46743717789649963\n",
      "2/2 [==============================] - 1s 17ms/step - loss: 0.2624 - mse: 0.2624 - mae: 0.4063\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch269.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2621 - mse: 0.2621 - mae: 0.4160\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2239 - mse: 0.2239 - mae: 0.3914\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3045 - mse: 0.3045 - mae: 0.4506\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3117 - mse: 0.3117 - mae: 0.4789\n",
      "train set score : mse - 0.26207098364830017 / mae - 0.41603565216064453\n",
      "dev set score : mse - 0.22393359243869781 / mae - 0.3913779854774475\n",
      "test1 set score : mse - 0.3045381009578705 / mae - 0.4505787491798401\n",
      "test2 set score : mse - 0.3117485046386719 / mae - 0.47887682914733887\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2621 - mse: 0.2621 - mae: 0.4147\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch270.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2611 - mse: 0.2611 - mae: 0.4108\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2150 - mse: 0.2150 - mae: 0.3809\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3052 - mse: 0.3052 - mae: 0.4490\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3070 - mse: 0.3070 - mae: 0.4728\n",
      "train set score : mse - 0.26110318303108215 / mae - 0.410821795463562\n",
      "dev set score : mse - 0.21497899293899536 / mae - 0.3808898329734802\n",
      "test1 set score : mse - 0.3052273690700531 / mae - 0.4490039646625519\n",
      "test2 set score : mse - 0.3069523572921753 / mae - 0.472767174243927\n",
      "2/2 [==============================] - 1s 11ms/step - loss: 0.2616 - mse: 0.2616 - mae: 0.4085\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch271.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2609 - mse: 0.2609 - mae: 0.4105\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2151 - mse: 0.2151 - mae: 0.3810\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3051 - mse: 0.3051 - mae: 0.4490\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3066 - mse: 0.3066 - mae: 0.4724\n",
      "train set score : mse - 0.26087987422943115 / mae - 0.4105440676212311\n",
      "dev set score : mse - 0.21507515013217926 / mae - 0.3810197114944458\n",
      "test1 set score : mse - 0.3051338195800781 / mae - 0.4489559829235077\n",
      "test2 set score : mse - 0.3065860867500305 / mae - 0.47243908047676086\n",
      "2/2 [==============================] - 1s 19ms/step - loss: 0.2620 - mse: 0.2620 - mae: 0.4146\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch272.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2608 - mse: 0.2608 - mae: 0.4065\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2085 - mse: 0.2085 - mae: 0.3728\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3066 - mse: 0.3066 - mae: 0.4483\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3025 - mse: 0.3025 - mae: 0.4668\n",
      "train set score : mse - 0.26083236932754517 / mae - 0.4065406024456024\n",
      "dev set score : mse - 0.20845045149326324 / mae - 0.3728019893169403\n",
      "test1 set score : mse - 0.30662402510643005 / mae - 0.4483240246772766\n",
      "test2 set score : mse - 0.3025076687335968 / mae - 0.46683722734451294\n",
      "2/2 [==============================] - 1s 12ms/step - loss: 0.2615 - mse: 0.2615 - mae: 0.4044\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch273.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2604 - mse: 0.2604 - mae: 0.4096\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2145 - mse: 0.2145 - mae: 0.3803\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3051 - mse: 0.3051 - mae: 0.4488\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3055 - mse: 0.3055 - mae: 0.4712\n",
      "train set score : mse - 0.26043185591697693 / mae - 0.40961959958076477\n",
      "dev set score : mse - 0.21451126039028168 / mae - 0.38028448820114136\n",
      "test1 set score : mse - 0.3051304519176483 / mae - 0.44876259565353394\n",
      "test2 set score : mse - 0.305510014295578 / mae - 0.4711763858795166\n",
      "2/2 [==============================] - 1s 12ms/step - loss: 0.2606 - mse: 0.2606 - mae: 0.4116\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch274.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2605 - mse: 0.2605 - mae: 0.4118\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2190 - mse: 0.2190 - mae: 0.3857\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3047 - mse: 0.3047 - mae: 0.4495\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3070 - mse: 0.3070 - mae: 0.4735\n",
      "train set score : mse - 0.2604599595069885 / mae - 0.41178399324417114\n",
      "dev set score : mse - 0.2190234363079071 / mae - 0.38572779297828674\n",
      "test1 set score : mse - 0.3046763241291046 / mae - 0.4495120644569397\n",
      "test2 set score : mse - 0.30698785185813904 / mae - 0.4734586775302887\n",
      "2/2 [==============================] - 1s 18ms/step - loss: 0.2605 - mse: 0.2605 - mae: 0.4116\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch275.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2627 - mse: 0.2627 - mae: 0.3985\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1963 - mse: 0.1963 - mae: 0.3575\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3126 - mse: 0.3126 - mae: 0.4486\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2936 - mse: 0.2936 - mae: 0.4540\n",
      "train set score : mse - 0.2627374231815338 / mae - 0.3984953761100769\n",
      "dev set score : mse - 0.19632044434547424 / mae - 0.3575131297111511\n",
      "test1 set score : mse - 0.3125765919685364 / mae - 0.4485924243927002\n",
      "test2 set score : mse - 0.29356127977371216 / mae - 0.4539921283721924\n",
      "2/2 [==============================] - 1s 14ms/step - loss: 0.2624 - mse: 0.2624 - mae: 0.3989\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch276.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2636 - mse: 0.2636 - mae: 0.4222\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2390 - mse: 0.2390 - mae: 0.4081\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3040 - mse: 0.3040 - mae: 0.4531\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3181 - mse: 0.3181 - mae: 0.4867\n",
      "train set score : mse - 0.2635853588581085 / mae - 0.4222375452518463\n",
      "dev set score : mse - 0.23902173340320587 / mae - 0.4080873429775238\n",
      "test1 set score : mse - 0.30402839183807373 / mae - 0.45305588841438293\n",
      "test2 set score : mse - 0.3181441128253937 / mae - 0.48674604296684265\n",
      "2/2 [==============================] - 1s 12ms/step - loss: 0.2625 - mse: 0.2625 - mae: 0.4193\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch277.h5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2606 - mse: 0.2606 - mae: 0.4015\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2027 - mse: 0.2027 - mae: 0.3655\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3085 - mse: 0.3085 - mae: 0.4479\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2972 - mse: 0.2972 - mae: 0.4598\n",
      "train set score : mse - 0.26062172651290894 / mae - 0.40148934721946716\n",
      "dev set score : mse - 0.20267875492572784 / mae - 0.36549296975135803\n",
      "test1 set score : mse - 0.30850470066070557 / mae - 0.4479304850101471\n",
      "test2 set score : mse - 0.29716065526008606 / mae - 0.4597575068473816\n",
      "2/2 [==============================] - 1s 18ms/step - loss: 0.2683 - mse: 0.2683 - mae: 0.3992\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch278.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2641 - mse: 0.2641 - mae: 0.4243\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2436 - mse: 0.2436 - mae: 0.4131\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3035 - mse: 0.3035 - mae: 0.4536\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3219 - mse: 0.3219 - mae: 0.4908\n",
      "train set score : mse - 0.264146089553833 / mae - 0.4243393540382385\n",
      "dev set score : mse - 0.2435794174671173 / mae - 0.4130963087081909\n",
      "test1 set score : mse - 0.3034777045249939 / mae - 0.45364946126937866\n",
      "test2 set score : mse - 0.3219245374202728 / mae - 0.49083104729652405\n",
      "2/2 [==============================] - 1s 13ms/step - loss: 0.2674 - mse: 0.2674 - mae: 0.4303\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch279.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2608 - mse: 0.2608 - mae: 0.4008\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2022 - mse: 0.2022 - mae: 0.3649\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3071 - mse: 0.3071 - mae: 0.4470\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2987 - mse: 0.2987 - mae: 0.4613\n",
      "train set score : mse - 0.26077666878700256 / mae - 0.40081164240837097\n",
      "dev set score : mse - 0.20222532749176025 / mae - 0.3648619055747986\n",
      "test1 set score : mse - 0.3071470260620117 / mae - 0.4470025897026062\n",
      "test2 set score : mse - 0.29873067140579224 / mae - 0.46134158968925476\n",
      "2/2 [==============================] - 1s 13ms/step - loss: 0.2676 - mse: 0.2676 - mae: 0.3974\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch280.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2593 - mse: 0.2593 - mae: 0.4069\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2132 - mse: 0.2132 - mae: 0.3785\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3028 - mse: 0.3028 - mae: 0.4469\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3064 - mse: 0.3064 - mae: 0.4718\n",
      "train set score : mse - 0.25934654474258423 / mae - 0.4069058299064636\n",
      "dev set score : mse - 0.2132125049829483 / mae - 0.3785356283187866\n",
      "test1 set score : mse - 0.30277934670448303 / mae - 0.4469410479068756\n",
      "test2 set score : mse - 0.3063805401325226 / mae - 0.4718131422996521\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2598 - mse: 0.2598 - mae: 0.4143\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch281.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2643 - mse: 0.2643 - mae: 0.4264\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2481 - mse: 0.2481 - mae: 0.4181\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3018 - mse: 0.3018 - mae: 0.4537\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3283 - mse: 0.3283 - mae: 0.4974\n",
      "train set score : mse - 0.2642930746078491 / mae - 0.4263845384120941\n",
      "dev set score : mse - 0.2480715811252594 / mae - 0.41808703541755676\n",
      "test1 set score : mse - 0.3018306493759155 / mae - 0.4536772072315216\n",
      "test2 set score : mse - 0.3282637298107147 / mae - 0.49739977717399597\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 0.2610 - mse: 0.2610 - mae: 0.4140\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch282.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2669 - mse: 0.2669 - mae: 0.3936\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1900 - mse: 0.1900 - mae: 0.3489\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3133 - mse: 0.3133 - mae: 0.4469\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2930 - mse: 0.2930 - mae: 0.4512\n",
      "train set score : mse - 0.2669190764427185 / mae - 0.39355069398880005\n",
      "dev set score : mse - 0.18995730578899384 / mae - 0.34893739223480225\n",
      "test1 set score : mse - 0.3133321702480316 / mae - 0.44691815972328186\n",
      "test2 set score : mse - 0.2929518520832062 / mae - 0.45117294788360596\n",
      "2/2 [==============================] - 1s 14ms/step - loss: 0.2636 - mse: 0.2636 - mae: 0.3958\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch283.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2659 - mse: 0.2659 - mae: 0.4294\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2547 - mse: 0.2547 - mae: 0.4250\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3027 - mse: 0.3027 - mae: 0.4553\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3309 - mse: 0.3309 - mae: 0.5003\n",
      "train set score : mse - 0.2658537030220032 / mae - 0.42940592765808105\n",
      "dev set score : mse - 0.2546585202217102 / mae - 0.4250253438949585\n",
      "test1 set score : mse - 0.30271750688552856 / mae - 0.45525962114334106\n",
      "test2 set score : mse - 0.33090513944625854 / mae - 0.5002902746200562\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2643 - mse: 0.2643 - mae: 0.4247\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch284.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2592 - mse: 0.2592 - mae: 0.4035\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2084 - mse: 0.2084 - mae: 0.3728\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3034 - mse: 0.3034 - mae: 0.4464\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3015 - mse: 0.3015 - mae: 0.4661\n",
      "train set score : mse - 0.25918906927108765 / mae - 0.40347838401794434\n",
      "dev set score : mse - 0.20837149024009705 / mae - 0.37276071310043335\n",
      "test1 set score : mse - 0.30340269207954407 / mae - 0.44640836119651794\n",
      "test2 set score : mse - 0.30148816108703613 / mae - 0.466101735830307\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2599 - mse: 0.2599 - mae: 0.4014\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch285.h5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2584 - mse: 0.2584 - mae: 0.4063\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2142 - mse: 0.2142 - mae: 0.3800\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3025 - mse: 0.3025 - mae: 0.4471\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3033 - mse: 0.3033 - mae: 0.4692\n",
      "train set score : mse - 0.2584347128868103 / mae - 0.40631264448165894\n",
      "dev set score : mse - 0.21421056985855103 / mae - 0.37998443841934204\n",
      "test1 set score : mse - 0.3024926483631134 / mae - 0.4470871686935425\n",
      "test2 set score : mse - 0.30331963300704956 / mae - 0.4691518545150757\n",
      "2/2 [==============================] - 1s 13ms/step - loss: 0.2583 - mse: 0.2583 - mae: 0.4065\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch286.h5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2610 - mse: 0.2610 - mae: 0.4191\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2385 - mse: 0.2385 - mae: 0.4076\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3017 - mse: 0.3017 - mae: 0.4517\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3162 - mse: 0.3162 - mae: 0.4851\n",
      "train set score : mse - 0.2609826922416687 / mae - 0.4191184341907501\n",
      "dev set score : mse - 0.2384561449289322 / mae - 0.40760254859924316\n",
      "test1 set score : mse - 0.3017128109931946 / mae - 0.4517107903957367\n",
      "test2 set score : mse - 0.3161703646183014 / mae - 0.4850779175758362\n",
      "2/2 [==============================] - 1s 14ms/step - loss: 0.2598 - mse: 0.2598 - mae: 0.4154\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch287.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2595 - mse: 0.2595 - mae: 0.3989\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2027 - mse: 0.2027 - mae: 0.3653\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3071 - mse: 0.3071 - mae: 0.4471\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2944 - mse: 0.2944 - mae: 0.4568\n",
      "train set score : mse - 0.25953608751296997 / mae - 0.398877888917923\n",
      "dev set score : mse - 0.2026856392621994 / mae - 0.36532771587371826\n",
      "test1 set score : mse - 0.3071288764476776 / mae - 0.4470856785774231\n",
      "test2 set score : mse - 0.29436811804771423 / mae - 0.45683717727661133\n",
      "2/2 [==============================] - 1s 13ms/step - loss: 0.2605 - mse: 0.2605 - mae: 0.3975\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch288.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2591 - mse: 0.2591 - mae: 0.4133\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2305 - mse: 0.2305 - mae: 0.3985\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3028 - mse: 0.3028 - mae: 0.4505\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3084 - mse: 0.3084 - mae: 0.4761\n",
      "train set score : mse - 0.2591365575790405 / mae - 0.41333913803100586\n",
      "dev set score : mse - 0.2304968386888504 / mae - 0.39849480986595154\n",
      "test1 set score : mse - 0.3028026521205902 / mae - 0.45048829913139343\n",
      "test2 set score : mse - 0.3083551526069641 / mae - 0.47610312700271606\n",
      "2/2 [==============================] - 1s 11ms/step - loss: 0.2617 - mse: 0.2617 - mae: 0.4184\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch289.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2585 - mse: 0.2585 - mae: 0.3997\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2059 - mse: 0.2059 - mae: 0.3692\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3067 - mse: 0.3067 - mae: 0.4475\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2947 - mse: 0.2947 - mae: 0.4577\n",
      "train set score : mse - 0.2585132122039795 / mae - 0.39973363280296326\n",
      "dev set score : mse - 0.20588533580303192 / mae - 0.36915910243988037\n",
      "test1 set score : mse - 0.30671581625938416 / mae - 0.4474793076515198\n",
      "test2 set score : mse - 0.29466405510902405 / mae - 0.4576686918735504\n",
      "2/2 [==============================] - 1s 17ms/step - loss: 0.2626 - mse: 0.2626 - mae: 0.3963\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch290.h5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2575 - mse: 0.2575 - mae: 0.4050\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2161 - mse: 0.2161 - mae: 0.3818\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3039 - mse: 0.3039 - mae: 0.4480\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3002 - mse: 0.3002 - mae: 0.4657\n",
      "train set score : mse - 0.2575019299983978 / mae - 0.40500372648239136\n",
      "dev set score : mse - 0.2160859853029251 / mae - 0.3817976117134094\n",
      "test1 set score : mse - 0.303859680891037 / mae - 0.4479502737522125\n",
      "test2 set score : mse - 0.3001895844936371 / mae - 0.4656530022621155\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2570 - mse: 0.2570 - mae: 0.4089\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch291.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2616 - mse: 0.2616 - mae: 0.4204\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2444 - mse: 0.2444 - mae: 0.4136\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3029 - mse: 0.3029 - mae: 0.4532\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3169 - mse: 0.3169 - mae: 0.4859\n",
      "train set score : mse - 0.26156172156333923 / mae - 0.4203847348690033\n",
      "dev set score : mse - 0.2443772554397583 / mae - 0.4136468470096588\n",
      "test1 set score : mse - 0.3029184937477112 / mae - 0.45315828919410706\n",
      "test2 set score : mse - 0.31692662835121155 / mae - 0.4858665466308594\n",
      "2/2 [==============================] - 1s 12ms/step - loss: 0.2587 - mse: 0.2587 - mae: 0.4133\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch292.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2633 - mse: 0.2633 - mae: 0.3920\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1924 - mse: 0.1924 - mae: 0.3520\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3128 - mse: 0.3128 - mae: 0.4472\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2889 - mse: 0.2889 - mae: 0.4474\n",
      "train set score : mse - 0.2632799446582794 / mae - 0.39203402400016785\n",
      "dev set score : mse - 0.19240395724773407 / mae - 0.3520476520061493\n",
      "test1 set score : mse - 0.31284645199775696 / mae - 0.44723567366600037\n",
      "test2 set score : mse - 0.28891104459762573 / mae - 0.44737154245376587\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 0.2616 - mse: 0.2616 - mae: 0.3934\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch293.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2604 - mse: 0.2604 - mae: 0.4188\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2420 - mse: 0.2420 - mae: 0.4112\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3018 - mse: 0.3018 - mae: 0.4521\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3170 - mse: 0.3170 - mae: 0.4859\n",
      "train set score : mse - 0.2604268789291382 / mae - 0.41875043511390686\n",
      "dev set score : mse - 0.24203555285930634 / mae - 0.4111708700656891\n",
      "test1 set score : mse - 0.30184459686279297 / mae - 0.4521110951900482\n",
      "test2 set score : mse - 0.3170076310634613 / mae - 0.48585355281829834\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2655 - mse: 0.2655 - mae: 0.4264\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch294.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2601 - mse: 0.2601 - mae: 0.3951\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1988 - mse: 0.1988 - mae: 0.3602\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3077 - mse: 0.3077 - mae: 0.4460\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2934 - mse: 0.2934 - mae: 0.4546\n",
      "train set score : mse - 0.2601340413093567 / mae - 0.39505600929260254\n",
      "dev set score : mse - 0.19884322583675385 / mae - 0.3601975739002228\n",
      "test1 set score : mse - 0.30769112706184387 / mae - 0.44602376222610474\n",
      "test2 set score : mse - 0.293420672416687 / mae - 0.4545806646347046\n",
      "2/2 [==============================] - 1s 12ms/step - loss: 0.2652 - mse: 0.2652 - mae: 0.3910\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch295.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2573 - mse: 0.2573 - mae: 0.4019\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2115 - mse: 0.2115 - mae: 0.3761\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3022 - mse: 0.3022 - mae: 0.4459\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3017 - mse: 0.3017 - mae: 0.4665\n",
      "train set score : mse - 0.2572809159755707 / mae - 0.4019070565700531\n",
      "dev set score : mse - 0.2115420401096344 / mae - 0.3760834038257599\n",
      "test1 set score : mse - 0.3021780550479889 / mae - 0.4458552896976471\n",
      "test2 set score : mse - 0.3017290234565735 / mae - 0.46648481488227844\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 0.2572 - mse: 0.2572 - mae: 0.4110\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch296.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2642 - mse: 0.2642 - mae: 0.4273\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2581 - mse: 0.2581 - mae: 0.4282\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3024 - mse: 0.3024 - mae: 0.4552\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3306 - mse: 0.3306 - mae: 0.5000\n",
      "train set score : mse - 0.2641826570034027 / mae - 0.42733514308929443\n",
      "dev set score : mse - 0.2581140100955963 / mae - 0.4282343089580536\n",
      "test1 set score : mse - 0.3024134039878845 / mae - 0.455242782831192\n",
      "test2 set score : mse - 0.33064004778862 / mae - 0.4999977946281433\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2656 - mse: 0.2656 - mae: 0.4160\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch297.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2618 - mse: 0.2618 - mae: 0.3934\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1961 - mse: 0.1961 - mae: 0.3567\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3078 - mse: 0.3078 - mae: 0.4453\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2937 - mse: 0.2937 - mae: 0.4542\n",
      "train set score : mse - 0.26176130771636963 / mae - 0.3933514356613159\n",
      "dev set score : mse - 0.19605886936187744 / mae - 0.35666099190711975\n",
      "test1 set score : mse - 0.3077962398529053 / mae - 0.44532305002212524\n",
      "test2 set score : mse - 0.2937066853046417 / mae - 0.45417654514312744\n",
      "2/2 [==============================] - 1s 13ms/step - loss: 0.2586 - mse: 0.2586 - mae: 0.3971\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch298.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2635 - mse: 0.2635 - mae: 0.4262\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2563 - mse: 0.2563 - mae: 0.4265\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3023 - mse: 0.3023 - mae: 0.4549\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3278 - mse: 0.3278 - mae: 0.4975\n",
      "train set score : mse - 0.26347967982292175 / mae - 0.4261623024940491\n",
      "dev set score : mse - 0.2562863528728485 / mae - 0.4265047013759613\n",
      "test1 set score : mse - 0.3022533357143402 / mae - 0.4549219310283661\n",
      "test2 set score : mse - 0.3278169333934784 / mae - 0.49745211005210876\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2650 - mse: 0.2650 - mae: 0.4283\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch299.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2612 - mse: 0.2612 - mae: 0.3929\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1956 - mse: 0.1956 - mae: 0.3563\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3081 - mse: 0.3081 - mae: 0.4455\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2917 - mse: 0.2917 - mae: 0.4522\n",
      "train set score : mse - 0.26124638319015503 / mae - 0.3929332196712494\n",
      "dev set score : mse - 0.19560536742210388 / mae - 0.3563249111175537\n",
      "test1 set score : mse - 0.30809736251831055 / mae - 0.44552090764045715\n",
      "test2 set score : mse - 0.29172149300575256 / mae - 0.45217227935791016\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 0.2653 - mse: 0.2653 - mae: 0.3903\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch300.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2571 - mse: 0.2571 - mae: 0.3997\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2082 - mse: 0.2082 - mae: 0.3724\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3023 - mse: 0.3023 - mae: 0.4453\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2986 - mse: 0.2986 - mae: 0.4630\n",
      "train set score : mse - 0.2571263909339905 / mae - 0.39971038699150085\n",
      "dev set score : mse - 0.2082395702600479 / mae - 0.3723756670951843\n",
      "test1 set score : mse - 0.3023037016391754 / mae - 0.4453267455101013\n",
      "test2 set score : mse - 0.2986183762550354 / mae - 0.46300721168518066\n",
      "2/2 [==============================] - 1s 13ms/step - loss: 0.2593 - mse: 0.2593 - mae: 0.4116\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch301.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2637 - mse: 0.2637 - mae: 0.4266\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2582 - mse: 0.2582 - mae: 0.4285\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3025 - mse: 0.3025 - mae: 0.4554\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3275 - mse: 0.3275 - mae: 0.4973\n",
      "train set score : mse - 0.2636975347995758 / mae - 0.42663976550102234\n",
      "dev set score : mse - 0.25820493698120117 / mae - 0.428531289100647\n",
      "test1 set score : mse - 0.3025355041027069 / mae - 0.45538875460624695\n",
      "test2 set score : mse - 0.3274975121021271 / mae - 0.49730777740478516\n",
      "2/2 [==============================] - 1s 40ms/step - loss: 0.2577 - mse: 0.2577 - mae: 0.4169\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch302.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2691 - mse: 0.2691 - mae: 0.3880\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1851 - mse: 0.1851 - mae: 0.3424\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3169 - mse: 0.3169 - mae: 0.4471\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2859 - mse: 0.2859 - mae: 0.4413\n",
      "train set score : mse - 0.26905587315559387 / mae - 0.3880464434623718\n",
      "dev set score : mse - 0.18507546186447144 / mae - 0.3423939347267151\n",
      "test1 set score : mse - 0.3168739080429077 / mae - 0.44711247086524963\n",
      "test2 set score : mse - 0.2858956754207611 / mae - 0.4412780702114105\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2698 - mse: 0.2698 - mae: 0.3881\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch303.h5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2577 - mse: 0.2577 - mae: 0.4144\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2362 - mse: 0.2362 - mae: 0.4052\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2996 - mse: 0.2996 - mae: 0.4499\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3134 - mse: 0.3134 - mae: 0.4824\n",
      "train set score : mse - 0.2576945424079895 / mae - 0.4143788516521454\n",
      "dev set score : mse - 0.2361987680196762 / mae - 0.4052138030529022\n",
      "test1 set score : mse - 0.29962819814682007 / mae - 0.44986239075660706\n",
      "test2 set score : mse - 0.3134382367134094 / mae - 0.4824369549751282\n",
      "2/2 [==============================] - 1s 13ms/step - loss: 0.2617 - mse: 0.2617 - mae: 0.4224\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch304.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2586 - mse: 0.2586 - mae: 0.4172\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2412 - mse: 0.2412 - mae: 0.4108\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2998 - mse: 0.2998 - mae: 0.4510\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3164 - mse: 0.3164 - mae: 0.4860\n",
      "train set score : mse - 0.2586309611797333 / mae - 0.41718605160713196\n",
      "dev set score : mse - 0.24119065701961517 / mae - 0.4107949435710907\n",
      "test1 set score : mse - 0.29979225993156433 / mae - 0.45096901059150696\n",
      "test2 set score : mse - 0.316419780254364 / mae - 0.4859726130962372\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 0.2566 - mse: 0.2566 - mae: 0.4044\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch305.h5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2659 - mse: 0.2659 - mae: 0.3889\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1877 - mse: 0.1877 - mae: 0.3463\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3130 - mse: 0.3130 - mae: 0.4461\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2866 - mse: 0.2866 - mae: 0.4440\n",
      "train set score : mse - 0.26593533158302307 / mae - 0.388900488615036\n",
      "dev set score : mse - 0.18773292005062103 / mae - 0.34633880853652954\n",
      "test1 set score : mse - 0.3130407929420471 / mae - 0.4461202919483185\n",
      "test2 set score : mse - 0.2866060137748718 / mae - 0.44396379590034485\n",
      "2/2 [==============================] - 1s 13ms/step - loss: 0.2618 - mse: 0.2618 - mae: 0.3937\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch306.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2601 - mse: 0.2601 - mae: 0.4207\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2481 - mse: 0.2481 - mae: 0.4182\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3004 - mse: 0.3004 - mae: 0.4525\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3201 - mse: 0.3201 - mae: 0.4901\n",
      "train set score : mse - 0.2600702941417694 / mae - 0.42066866159439087\n",
      "dev set score : mse - 0.24807487428188324 / mae - 0.41824111342430115\n",
      "test1 set score : mse - 0.3004157543182373 / mae - 0.45252618193626404\n",
      "test2 set score : mse - 0.3201175332069397 / mae - 0.49010521173477173\n",
      "2/2 [==============================] - 1s 13ms/step - loss: 0.2596 - mse: 0.2596 - mae: 0.4174\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch307.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2556 - mse: 0.2556 - mae: 0.4066\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2223 - mse: 0.2223 - mae: 0.3897\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2992 - mse: 0.2992 - mae: 0.4467\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3048 - mse: 0.3048 - mae: 0.4724\n",
      "train set score : mse - 0.25564882159233093 / mae - 0.4066494405269623\n",
      "dev set score : mse - 0.22229231894016266 / mae - 0.38970381021499634\n",
      "test1 set score : mse - 0.2991810441017151 / mae - 0.446705162525177\n",
      "test2 set score : mse - 0.304753839969635 / mae - 0.4723881483078003\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 0.2567 - mse: 0.2567 - mae: 0.4026\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch308.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2559 - mse: 0.2559 - mae: 0.4001\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2105 - mse: 0.2105 - mae: 0.3755\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3011 - mse: 0.3011 - mae: 0.4452\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2976 - mse: 0.2976 - mae: 0.4629\n",
      "train set score : mse - 0.2558930218219757 / mae - 0.4000914692878723\n",
      "dev set score : mse - 0.21047887206077576 / mae - 0.3754810392856598\n",
      "test1 set score : mse - 0.3010808229446411 / mae - 0.4452176094055176\n",
      "test2 set score : mse - 0.29758375883102417 / mae - 0.4629060626029968\n",
      "2/2 [==============================] - 1s 13ms/step - loss: 0.2560 - mse: 0.2560 - mae: 0.4043\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch309.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2561 - mse: 0.2561 - mae: 0.4102\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2301 - mse: 0.2301 - mae: 0.3986\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2997 - mse: 0.2997 - mae: 0.4486\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3071 - mse: 0.3071 - mae: 0.4756\n",
      "train set score : mse - 0.25609442591667175 / mae - 0.4102229177951813\n",
      "dev set score : mse - 0.2300625890493393 / mae - 0.39858752489089966\n",
      "test1 set score : mse - 0.2997010052204132 / mae - 0.44857627153396606\n",
      "test2 set score : mse - 0.30708420276641846 / mae - 0.47563937306404114\n",
      "2/2 [==============================] - 1s 14ms/step - loss: 0.2566 - mse: 0.2566 - mae: 0.4062\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch310.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2554 - mse: 0.2554 - mae: 0.3992\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2104 - mse: 0.2104 - mae: 0.3752\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3022 - mse: 0.3022 - mae: 0.4457\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2956 - mse: 0.2956 - mae: 0.4605\n",
      "train set score : mse - 0.2554347813129425 / mae - 0.3992162048816681\n",
      "dev set score : mse - 0.2104148417711258 / mae - 0.37521442770957947\n",
      "test1 set score : mse - 0.3021504282951355 / mae - 0.4456838071346283\n",
      "test2 set score : mse - 0.2955774962902069 / mae - 0.46047189831733704\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 0.2554 - mse: 0.2554 - mae: 0.4015\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch311.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2552 - mse: 0.2552 - mae: 0.4061\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2243 - mse: 0.2243 - mae: 0.3917\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3010 - mse: 0.3010 - mae: 0.4478\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3018 - mse: 0.3018 - mae: 0.4691\n",
      "train set score : mse - 0.2551743686199188 / mae - 0.40614113211631775\n",
      "dev set score : mse - 0.22434154152870178 / mae - 0.3917466104030609\n",
      "test1 set score : mse - 0.30098217725753784 / mae - 0.44780656695365906\n",
      "test2 set score : mse - 0.30183646082878113 / mae - 0.46910595893859863\n",
      "2/2 [==============================] - 1s 12ms/step - loss: 0.2556 - mse: 0.2556 - mae: 0.4033\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch312.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2547 - mse: 0.2547 - mae: 0.4005\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2147 - mse: 0.2147 - mae: 0.3801\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3025 - mse: 0.3025 - mae: 0.4465\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2961 - mse: 0.2961 - mae: 0.4613\n",
      "train set score : mse - 0.2547462582588196 / mae - 0.4005071818828583\n",
      "dev set score : mse - 0.21469813585281372 / mae - 0.3801499903202057\n",
      "test1 set score : mse - 0.30254098773002625 / mae - 0.44654637575149536\n",
      "test2 set score : mse - 0.2960805296897888 / mae - 0.46132761240005493\n",
      "2/2 [==============================] - 1s 13ms/step - loss: 0.2558 - mse: 0.2558 - mae: 0.4049\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch313.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2546 - mse: 0.2546 - mae: 0.4013\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2169 - mse: 0.2169 - mae: 0.3827\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3028 - mse: 0.3028 - mae: 0.4470\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2965 - mse: 0.2965 - mae: 0.4619\n",
      "train set score : mse - 0.25456923246383667 / mae - 0.4013238847255707\n",
      "dev set score : mse - 0.2169034481048584 / mae - 0.3826879858970642\n",
      "test1 set score : mse - 0.30275511741638184 / mae - 0.44700202345848083\n",
      "test2 set score : mse - 0.296470046043396 / mae - 0.46192431449890137\n",
      "2/2 [==============================] - 1s 17ms/step - loss: 0.2545 - mse: 0.2545 - mae: 0.4007\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch314.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2552 - mse: 0.2552 - mae: 0.3959\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2071 - mse: 0.2071 - mae: 0.3706\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3048 - mse: 0.3048 - mae: 0.4462\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2919 - mse: 0.2919 - mae: 0.4549\n",
      "train set score : mse - 0.2551807761192322 / mae - 0.39587563276290894\n",
      "dev set score : mse - 0.20707006752490997 / mae - 0.370568186044693\n",
      "test1 set score : mse - 0.3048342168331146 / mae - 0.44617822766304016\n",
      "test2 set score : mse - 0.2918528914451599 / mae - 0.45493268966674805\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 0.2554 - mse: 0.2554 - mae: 0.3955\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch315.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2552 - mse: 0.2552 - mae: 0.4074\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2297 - mse: 0.2297 - mae: 0.3973\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3016 - mse: 0.3016 - mae: 0.4488\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3040 - mse: 0.3040 - mae: 0.4714\n",
      "train set score : mse - 0.2552089989185333 / mae - 0.40743452310562134\n",
      "dev set score : mse - 0.2296978086233139 / mae - 0.3973100185394287\n",
      "test1 set score : mse - 0.30161651968955994 / mae - 0.4487914443016052\n",
      "test2 set score : mse - 0.30398234724998474 / mae - 0.4713587760925293\n",
      "2/2 [==============================] - 1s 14ms/step - loss: 0.2556 - mse: 0.2556 - mae: 0.4088\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch316.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2541 - mse: 0.2541 - mae: 0.4001\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2163 - mse: 0.2163 - mae: 0.3817\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3025 - mse: 0.3025 - mae: 0.4465\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2973 - mse: 0.2973 - mae: 0.4623\n",
      "train set score : mse - 0.2540873885154724 / mae - 0.4000698924064636\n",
      "dev set score : mse - 0.21633195877075195 / mae - 0.38169005513191223\n",
      "test1 set score : mse - 0.30250784754753113 / mae - 0.44646570086479187\n",
      "test2 set score : mse - 0.29726848006248474 / mae - 0.4623405933380127\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2552 - mse: 0.2552 - mae: 0.3965\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch317.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2543 - mse: 0.2543 - mae: 0.3972\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2112 - mse: 0.2112 - mae: 0.3754\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3031 - mse: 0.3031 - mae: 0.4457\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2954 - mse: 0.2954 - mae: 0.4594\n",
      "train set score : mse - 0.2542552351951599 / mae - 0.39721938967704773\n",
      "dev set score : mse - 0.21124638617038727 / mae - 0.3754218518733978\n",
      "test1 set score : mse - 0.3030882477760315 / mae - 0.44571664929389954\n",
      "test2 set score : mse - 0.2954377830028534 / mae - 0.45942333340644836\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2564 - mse: 0.2564 - mae: 0.4056\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch318.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2541 - mse: 0.2541 - mae: 0.4040\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2242 - mse: 0.2242 - mae: 0.3909\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3007 - mse: 0.3007 - mae: 0.4470\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3032 - mse: 0.3032 - mae: 0.4698\n",
      "train set score : mse - 0.2540562152862549 / mae - 0.40403246879577637\n",
      "dev set score : mse - 0.2241659164428711 / mae - 0.39091235399246216\n",
      "test1 set score : mse - 0.30071941018104553 / mae - 0.4470016658306122\n",
      "test2 set score : mse - 0.3032130002975464 / mae - 0.46981772780418396\n",
      "2/2 [==============================] - 1s 12ms/step - loss: 0.2542 - mse: 0.2542 - mae: 0.4000\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch319.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2550 - mse: 0.2550 - mae: 0.3938\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2051 - mse: 0.2051 - mae: 0.3679\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3043 - mse: 0.3043 - mae: 0.4450\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2932 - mse: 0.2932 - mae: 0.4557\n",
      "train set score : mse - 0.25502631068229675 / mae - 0.3937767446041107\n",
      "dev set score : mse - 0.20514017343521118 / mae - 0.3678530752658844\n",
      "test1 set score : mse - 0.3043002486228943 / mae - 0.44504019618034363\n",
      "test2 set score : mse - 0.29321911931037903 / mae - 0.45574450492858887\n",
      "2/2 [==============================] - 1s 17ms/step - loss: 0.2541 - mse: 0.2541 - mae: 0.3965\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch320.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2555 - mse: 0.2555 - mae: 0.4104\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2366 - mse: 0.2366 - mae: 0.4049\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3006 - mse: 0.3006 - mae: 0.4494\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3104 - mse: 0.3104 - mae: 0.4786\n",
      "train set score : mse - 0.2555485963821411 / mae - 0.410442590713501\n",
      "dev set score : mse - 0.23661543428897858 / mae - 0.40487140417099\n",
      "test1 set score : mse - 0.30055394768714905 / mae - 0.44943007826805115\n",
      "test2 set score : mse - 0.3103690445423126 / mae - 0.47857317328453064\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 0.2549 - mse: 0.2549 - mae: 0.4086\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch321.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2541 - mse: 0.2541 - mae: 0.3953\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2089 - mse: 0.2089 - mae: 0.3725\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3029 - mse: 0.3029 - mae: 0.4450\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2954 - mse: 0.2954 - mae: 0.4589\n",
      "train set score : mse - 0.25409290194511414 / mae - 0.39531782269477844\n",
      "dev set score : mse - 0.20888669788837433 / mae - 0.3724925220012665\n",
      "test1 set score : mse - 0.302911639213562 / mae - 0.4449736177921295\n",
      "test2 set score : mse - 0.29539814591407776 / mae - 0.4588780999183655\n",
      "2/2 [==============================] - 1s 13ms/step - loss: 0.2540 - mse: 0.2540 - mae: 0.3962\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch322.h5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2534 - mse: 0.2534 - mae: 0.3981\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2144 - mse: 0.2144 - mae: 0.3793\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3017 - mse: 0.3017 - mae: 0.4454\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2979 - mse: 0.2979 - mae: 0.4626\n",
      "train set score : mse - 0.25337594747543335 / mae - 0.3980570137500763\n",
      "dev set score : mse - 0.21436737477779388 / mae - 0.3792589604854584\n",
      "test1 set score : mse - 0.30171602964401245 / mae - 0.44539788365364075\n",
      "test2 set score : mse - 0.29791492223739624 / mae - 0.4626275599002838\n",
      "2/2 [==============================] - 1s 20ms/step - loss: 0.2553 - mse: 0.2553 - mae: 0.4044\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch323.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2532 - mse: 0.2532 - mae: 0.3983\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2155 - mse: 0.2155 - mae: 0.3806\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3018 - mse: 0.3018 - mae: 0.4456\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2979 - mse: 0.2979 - mae: 0.4627\n",
      "train set score : mse - 0.2531712055206299 / mae - 0.39834141731262207\n",
      "dev set score : mse - 0.21545527875423431 / mae - 0.38056156039237976\n",
      "test1 set score : mse - 0.3017810881137848 / mae - 0.44562047719955444\n",
      "test2 set score : mse - 0.2978508770465851 / mae - 0.46267831325531006\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2534 - mse: 0.2534 - mae: 0.3959\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch324.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2535 - mse: 0.2535 - mae: 0.3953\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2100 - mse: 0.2100 - mae: 0.3739\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3029 - mse: 0.3029 - mae: 0.4451\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2948 - mse: 0.2948 - mae: 0.4584\n",
      "train set score : mse - 0.2534600794315338 / mae - 0.3953266739845276\n",
      "dev set score : mse - 0.20999285578727722 / mae - 0.37394222617149353\n",
      "test1 set score : mse - 0.30286145210266113 / mae - 0.4451446831226349\n",
      "test2 set score : mse - 0.2948237657546997 / mae - 0.4584251046180725\n",
      "2/2 [==============================] - 1s 14ms/step - loss: 0.2531 - mse: 0.2531 - mae: 0.3960\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch325.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2549 - mse: 0.2549 - mae: 0.4090\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2360 - mse: 0.2360 - mae: 0.4042\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3012 - mse: 0.3012 - mae: 0.4495\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3079 - mse: 0.3079 - mae: 0.4758\n",
      "train set score : mse - 0.2548936903476715 / mae - 0.4090002477169037\n",
      "dev set score : mse - 0.23600910604000092 / mae - 0.4041624665260315\n",
      "test1 set score : mse - 0.30120232701301575 / mae - 0.44952070713043213\n",
      "test2 set score : mse - 0.30785736441612244 / mae - 0.4757888615131378\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 0.2587 - mse: 0.2587 - mae: 0.4145\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch326.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2572 - mse: 0.2572 - mae: 0.3875\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1958 - mse: 0.1958 - mae: 0.3561\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3091 - mse: 0.3091 - mae: 0.4454\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2868 - mse: 0.2868 - mae: 0.4459\n",
      "train set score : mse - 0.25722721219062805 / mae - 0.38745447993278503\n",
      "dev set score : mse - 0.1958005130290985 / mae - 0.3560853898525238\n",
      "test1 set score : mse - 0.3091106712818146 / mae - 0.4453529715538025\n",
      "test2 set score : mse - 0.28682374954223633 / mae - 0.44592684507369995\n",
      "2/2 [==============================] - 1s 13ms/step - loss: 0.2590 - mse: 0.2590 - mae: 0.3863\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch327.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2527 - mse: 0.2527 - mae: 0.3966\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2138 - mse: 0.2138 - mae: 0.3786\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3021 - mse: 0.3021 - mae: 0.4454\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2960 - mse: 0.2960 - mae: 0.4604\n",
      "train set score : mse - 0.252747118473053 / mae - 0.39663752913475037\n",
      "dev set score : mse - 0.21378792822360992 / mae - 0.37861791253089905\n",
      "test1 set score : mse - 0.30205151438713074 / mae - 0.4453847110271454\n",
      "test2 set score : mse - 0.29603099822998047 / mae - 0.46041375398635864\n",
      "2/2 [==============================] - 1s 12ms/step - loss: 0.2592 - mse: 0.2592 - mae: 0.4094\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch328.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2534 - mse: 0.2534 - mae: 0.4053\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2298 - mse: 0.2298 - mae: 0.3975\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3000 - mse: 0.3000 - mae: 0.4476\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3054 - mse: 0.3054 - mae: 0.4728\n",
      "train set score : mse - 0.25335800647735596 / mae - 0.4053471088409424\n",
      "dev set score : mse - 0.22983184456825256 / mae - 0.397471159696579\n",
      "test1 set score : mse - 0.3000313937664032 / mae - 0.4475977420806885\n",
      "test2 set score : mse - 0.30538511276245117 / mae - 0.47280094027519226\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 0.2523 - mse: 0.2523 - mae: 0.3973\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch329.h5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2593 - mse: 0.2593 - mae: 0.3862\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1928 - mse: 0.1928 - mae: 0.3524\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3091 - mse: 0.3091 - mae: 0.4446\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2871 - mse: 0.2871 - mae: 0.4456\n",
      "train set score : mse - 0.25926586985588074 / mae - 0.3862169086933136\n",
      "dev set score : mse - 0.19277308881282806 / mae - 0.35236525535583496\n",
      "test1 set score : mse - 0.30909615755081177 / mae - 0.4445846378803253\n",
      "test2 set score : mse - 0.2871193587779999 / mae - 0.44556042551994324\n",
      "2/2 [==============================] - 1s 13ms/step - loss: 0.2570 - mse: 0.2570 - mae: 0.3924\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch330.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2559 - mse: 0.2559 - mae: 0.4135\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2445 - mse: 0.2445 - mae: 0.4137\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2998 - mse: 0.2998 - mae: 0.4508\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3153 - mse: 0.3153 - mae: 0.4845\n",
      "train set score : mse - 0.2558647394180298 / mae - 0.41347846388816833\n",
      "dev set score : mse - 0.24447934329509735 / mae - 0.41366496682167053\n",
      "test1 set score : mse - 0.2998318672180176 / mae - 0.45075276494026184\n",
      "test2 set score : mse - 0.3153464198112488 / mae - 0.48446500301361084\n",
      "2/2 [==============================] - 1s 11ms/step - loss: 0.2549 - mse: 0.2549 - mae: 0.4111\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch331.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2538 - mse: 0.2538 - mae: 0.3927\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2061 - mse: 0.2061 - mae: 0.3693\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3018 - mse: 0.3018 - mae: 0.4437\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2943 - mse: 0.2943 - mae: 0.4575\n",
      "train set score : mse - 0.2537865936756134 / mae - 0.3927364945411682\n",
      "dev set score : mse - 0.20608888566493988 / mae - 0.36927634477615356\n",
      "test1 set score : mse - 0.3017701208591461 / mae - 0.44368353486061096\n",
      "test2 set score : mse - 0.29434263706207275 / mae - 0.45747461915016174\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 0.2540 - mse: 0.2540 - mae: 0.3920\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch332.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2523 - mse: 0.2523 - mae: 0.3980\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2160 - mse: 0.2160 - mae: 0.3816\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2995 - mse: 0.2995 - mae: 0.4446\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2990 - mse: 0.2990 - mae: 0.4645\n",
      "train set score : mse - 0.2522754669189453 / mae - 0.39795562624931335\n",
      "dev set score : mse - 0.2160240262746811 / mae - 0.38161712884902954\n",
      "test1 set score : mse - 0.29951900243759155 / mae - 0.4446459114551544\n",
      "test2 set score : mse - 0.299042284488678 / mae - 0.46454206109046936\n",
      "2/2 [==============================] - 1s 14ms/step - loss: 0.2527 - mse: 0.2527 - mae: 0.4021\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch333.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2530 - mse: 0.2530 - mae: 0.4058\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2310 - mse: 0.2310 - mae: 0.3991\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2992 - mse: 0.2992 - mae: 0.4476\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3057 - mse: 0.3057 - mae: 0.4737\n",
      "train set score : mse - 0.2529744505882263 / mae - 0.40580928325653076\n",
      "dev set score : mse - 0.23095504939556122 / mae - 0.39905691146850586\n",
      "test1 set score : mse - 0.2992039620876312 / mae - 0.4475545287132263\n",
      "test2 set score : mse - 0.30569660663604736 / mae - 0.47365912795066833\n",
      "2/2 [==============================] - 1s 13ms/step - loss: 0.2523 - mse: 0.2523 - mae: 0.4011\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch334.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2533 - mse: 0.2533 - mae: 0.3916\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2049 - mse: 0.2049 - mae: 0.3681\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3029 - mse: 0.3029 - mae: 0.4442\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2912 - mse: 0.2912 - mae: 0.4539\n",
      "train set score : mse - 0.2533423900604248 / mae - 0.39163196086883545\n",
      "dev set score : mse - 0.20493493974208832 / mae - 0.36805906891822815\n",
      "test1 set score : mse - 0.30293816328048706 / mae - 0.4442155659198761\n",
      "test2 set score : mse - 0.2912428081035614 / mae - 0.4538761079311371\n",
      "2/2 [==============================] - 1s 23ms/step - loss: 0.2540 - mse: 0.2540 - mae: 0.3910\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch335.h5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2535 - mse: 0.2535 - mae: 0.4075\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2355 - mse: 0.2355 - mae: 0.4039\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3002 - mse: 0.3002 - mae: 0.4490\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3062 - mse: 0.3062 - mae: 0.4744\n",
      "train set score : mse - 0.25352761149406433 / mae - 0.40751418471336365\n",
      "dev set score : mse - 0.23548062145709991 / mae - 0.40387991070747375\n",
      "test1 set score : mse - 0.30020639300346375 / mae - 0.4489848017692566\n",
      "test2 set score : mse - 0.3062490224838257 / mae - 0.4743995666503906\n",
      "2/2 [==============================] - 1s 14ms/step - loss: 0.2536 - mse: 0.2536 - mae: 0.4057\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch336.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2520 - mse: 0.2520 - mae: 0.4018\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2259 - mse: 0.2259 - mae: 0.3930\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3004 - mse: 0.3004 - mae: 0.4469\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3005 - mse: 0.3005 - mae: 0.4671\n",
      "train set score : mse - 0.2520092725753784 / mae - 0.40175074338912964\n",
      "dev set score : mse - 0.22588364779949188 / mae - 0.39297446608543396\n",
      "test1 set score : mse - 0.3003678619861603 / mae - 0.44693252444267273\n",
      "test2 set score : mse - 0.3005320727825165 / mae - 0.4671453535556793\n",
      "2/2 [==============================] - 1s 30ms/step - loss: 0.2526 - mse: 0.2526 - mae: 0.4031\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch337.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2537 - mse: 0.2537 - mae: 0.3893\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2022 - mse: 0.2022 - mae: 0.3644\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3048 - mse: 0.3048 - mae: 0.4445\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2887 - mse: 0.2887 - mae: 0.4500\n",
      "train set score : mse - 0.25371676683425903 / mae - 0.38933396339416504\n",
      "dev set score : mse - 0.2022399753332138 / mae - 0.36435315012931824\n",
      "test1 set score : mse - 0.3048286437988281 / mae - 0.44451427459716797\n",
      "test2 set score : mse - 0.2886897921562195 / mae - 0.45001763105392456\n",
      "2/2 [==============================] - 1s 17ms/step - loss: 0.2535 - mse: 0.2535 - mae: 0.3897\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch338.h5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2514 - mse: 0.2514 - mae: 0.3987\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2206 - mse: 0.2206 - mae: 0.3868\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3007 - mse: 0.3007 - mae: 0.4460\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2976 - mse: 0.2976 - mae: 0.4632\n",
      "train set score : mse - 0.25144511461257935 / mae - 0.3986964225769043\n",
      "dev set score : mse - 0.22062525153160095 / mae - 0.3868034780025482\n",
      "test1 set score : mse - 0.3006649613380432 / mae - 0.44595667719841003\n",
      "test2 set score : mse - 0.2975526452064514 / mae - 0.46315595507621765\n",
      "2/2 [==============================] - 1s 14ms/step - loss: 0.2530 - mse: 0.2530 - mae: 0.4039\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch339.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2514 - mse: 0.2514 - mae: 0.3991\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2219 - mse: 0.2219 - mae: 0.3882\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3003 - mse: 0.3003 - mae: 0.4459\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2986 - mse: 0.2986 - mae: 0.4644\n",
      "train set score : mse - 0.2513577938079834 / mae - 0.39908042550086975\n",
      "dev set score : mse - 0.221909299492836 / mae - 0.38818198442459106\n",
      "test1 set score : mse - 0.3002980649471283 / mae - 0.44594570994377136\n",
      "test2 set score : mse - 0.29861459136009216 / mae - 0.46436867117881775\n",
      "2/2 [==============================] - 1s 11ms/step - loss: 0.2509 - mse: 0.2509 - mae: 0.3970\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch340.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2535 - mse: 0.2535 - mae: 0.3887\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2022 - mse: 0.2022 - mae: 0.3641\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3047 - mse: 0.3047 - mae: 0.4443\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2889 - mse: 0.2889 - mae: 0.4501\n",
      "train set score : mse - 0.25351208448410034 / mae - 0.38869309425354004\n",
      "dev set score : mse - 0.20216986536979675 / mae - 0.3640752136707306\n",
      "test1 set score : mse - 0.30469080805778503 / mae - 0.44427216053009033\n",
      "test2 set score : mse - 0.28892719745635986 / mae - 0.45008090138435364\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 0.2528 - mse: 0.2528 - mae: 0.3898\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch341.h5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2529 - mse: 0.2529 - mae: 0.4067\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2367 - mse: 0.2367 - mae: 0.4048\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3000 - mse: 0.3000 - mae: 0.4488\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3067 - mse: 0.3067 - mae: 0.4746\n",
      "train set score : mse - 0.25290557742118835 / mae - 0.40672367811203003\n",
      "dev set score : mse - 0.2366989254951477 / mae - 0.40481072664260864\n",
      "test1 set score : mse - 0.3000354766845703 / mae - 0.4488048553466797\n",
      "test2 set score : mse - 0.30674266815185547 / mae - 0.47459399700164795\n",
      "2/2 [==============================] - 1s 14ms/step - loss: 0.2561 - mse: 0.2561 - mae: 0.4120\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch342.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2525 - mse: 0.2525 - mae: 0.3901\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2052 - mse: 0.2052 - mae: 0.3679\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3030 - mse: 0.3030 - mae: 0.4440\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2909 - mse: 0.2909 - mae: 0.4531\n",
      "train set score : mse - 0.25251060724258423 / mae - 0.39010176062583923\n",
      "dev set score : mse - 0.20515944063663483 / mae - 0.3679007291793823\n",
      "test1 set score : mse - 0.3030243217945099 / mae - 0.44396668672561646\n",
      "test2 set score : mse - 0.2909487783908844 / mae - 0.4531098008155823\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2533 - mse: 0.2533 - mae: 0.3875\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch343.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2520 - mse: 0.2520 - mae: 0.3912\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2074 - mse: 0.2074 - mae: 0.3707\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3019 - mse: 0.3019 - mae: 0.4438\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2925 - mse: 0.2925 - mae: 0.4554\n",
      "train set score : mse - 0.2519945204257965 / mae - 0.3911776840686798\n",
      "dev set score : mse - 0.20735764503479004 / mae - 0.37067800760269165\n",
      "test1 set score : mse - 0.3019075393676758 / mae - 0.44381803274154663\n",
      "test2 set score : mse - 0.2925131618976593 / mae - 0.45538583397865295\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 0.2520 - mse: 0.2520 - mae: 0.3973\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch344.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2535 - mse: 0.2535 - mae: 0.4092\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2416 - mse: 0.2416 - mae: 0.4102\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2996 - mse: 0.2996 - mae: 0.4497\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3106 - mse: 0.3106 - mae: 0.4791\n",
      "train set score : mse - 0.2534868121147156 / mae - 0.40921998023986816\n",
      "dev set score : mse - 0.24161924421787262 / mae - 0.41024377942085266\n",
      "test1 set score : mse - 0.2996351420879364 / mae - 0.4496658444404602\n",
      "test2 set score : mse - 0.3105921149253845 / mae - 0.4790850877761841\n",
      "2/2 [==============================] - 1s 19ms/step - loss: 0.2551 - mse: 0.2551 - mae: 0.4029\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch345.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2521 - mse: 0.2521 - mae: 0.3908\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2070 - mse: 0.2070 - mae: 0.3701\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3013 - mse: 0.3013 - mae: 0.4433\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2934 - mse: 0.2934 - mae: 0.4563\n",
      "train set score : mse - 0.2521043121814728 / mae - 0.390762597322464\n",
      "dev set score : mse - 0.20699438452720642 / mae - 0.3701271414756775\n",
      "test1 set score : mse - 0.3013330399990082 / mae - 0.4433394968509674\n",
      "test2 set score : mse - 0.2934381365776062 / mae - 0.4563175439834595\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2529 - mse: 0.2529 - mae: 0.3984\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch346.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2514 - mse: 0.2514 - mae: 0.4036\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2317 - mse: 0.2317 - mae: 0.3994\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2984 - mse: 0.2984 - mae: 0.4468\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3064 - mse: 0.3064 - mae: 0.4740\n",
      "train set score : mse - 0.25141072273254395 / mae - 0.40363621711730957\n",
      "dev set score : mse - 0.23170123994350433 / mae - 0.39942193031311035\n",
      "test1 set score : mse - 0.2983655035495758 / mae - 0.4468070864677429\n",
      "test2 set score : mse - 0.30637025833129883 / mae - 0.4739525020122528\n",
      "2/2 [==============================] - 1s 17ms/step - loss: 0.2534 - mse: 0.2534 - mae: 0.3994\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch347.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2508 - mse: 0.2508 - mae: 0.3938\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2135 - mse: 0.2135 - mae: 0.3783\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2998 - mse: 0.2998 - mae: 0.4439\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2964 - mse: 0.2964 - mae: 0.4608\n",
      "train set score : mse - 0.2508096694946289 / mae - 0.3938080668449402\n",
      "dev set score : mse - 0.21352557837963104 / mae - 0.3783200979232788\n",
      "test1 set score : mse - 0.2998180389404297 / mae - 0.44385868310928345\n",
      "test2 set score : mse - 0.2963751256465912 / mae - 0.4607771039009094\n",
      "2/2 [==============================] - 1s 17ms/step - loss: 0.2535 - mse: 0.2535 - mae: 0.4025\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch348.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2506 - mse: 0.2506 - mae: 0.4001\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2260 - mse: 0.2260 - mae: 0.3930\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2989 - mse: 0.2989 - mae: 0.4459\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3020 - mse: 0.3020 - mae: 0.4686\n",
      "train set score : mse - 0.25060367584228516 / mae - 0.4000648558139801\n",
      "dev set score : mse - 0.22601096332073212 / mae - 0.39298275113105774\n",
      "test1 set score : mse - 0.298909455537796 / mae - 0.44589826464653015\n",
      "test2 set score : mse - 0.3019549250602722 / mae - 0.46860143542289734\n",
      "2/2 [==============================] - 1s 13ms/step - loss: 0.2501 - mse: 0.2501 - mae: 0.3986\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch349.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2540 - mse: 0.2540 - mae: 0.3859\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1991 - mse: 0.1991 - mae: 0.3603\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3051 - mse: 0.3051 - mae: 0.4436\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2879 - mse: 0.2879 - mae: 0.4482\n",
      "train set score : mse - 0.25396597385406494 / mae - 0.3859241306781769\n",
      "dev set score : mse - 0.19912686944007874 / mae - 0.3603382706642151\n",
      "test1 set score : mse - 0.3050954043865204 / mae - 0.44363221526145935\n",
      "test2 set score : mse - 0.28793203830718994 / mae - 0.4481845200061798\n",
      "2/2 [==============================] - 1s 17ms/step - loss: 0.2537 - mse: 0.2537 - mae: 0.3911\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch350.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2503 - mse: 0.2503 - mae: 0.3987\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2244 - mse: 0.2244 - mae: 0.3910\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2996 - mse: 0.2996 - mae: 0.4459\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2996 - mse: 0.2996 - mae: 0.4657\n",
      "train set score : mse - 0.25027981400489807 / mae - 0.3987146317958832\n",
      "dev set score : mse - 0.22437161207199097 / mae - 0.39103996753692627\n",
      "test1 set score : mse - 0.2996046245098114 / mae - 0.44585877656936646\n",
      "test2 set score : mse - 0.299564927816391 / mae - 0.46569210290908813\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 0.2507 - mse: 0.2507 - mae: 0.4004\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch351.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2502 - mse: 0.2502 - mae: 0.3929\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2140 - mse: 0.2140 - mae: 0.3789\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3009 - mse: 0.3009 - mae: 0.4444\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2939 - mse: 0.2939 - mae: 0.4579\n",
      "train set score : mse - 0.2502029538154602 / mae - 0.39293450117111206\n",
      "dev set score : mse - 0.21404814720153809 / mae - 0.3788742125034332\n",
      "test1 set score : mse - 0.30093517899513245 / mae - 0.4444059729576111\n",
      "test2 set score : mse - 0.2939164340496063 / mae - 0.4579029083251953\n",
      "2/2 [==============================] - 1s 14ms/step - loss: 0.2506 - mse: 0.2506 - mae: 0.3914\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch352.h5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2499 - mse: 0.2499 - mae: 0.3946\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2181 - mse: 0.2181 - mae: 0.3835\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3006 - mse: 0.3006 - mae: 0.4450\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2956 - mse: 0.2956 - mae: 0.4602\n",
      "train set score : mse - 0.24990317225456238 / mae - 0.3946174681186676\n",
      "dev set score : mse - 0.21808739006519318 / mae - 0.3835282623767853\n",
      "test1 set score : mse - 0.30060631036758423 / mae - 0.44497331976890564\n",
      "test2 set score : mse - 0.2955613434314728 / mae - 0.4601883590221405\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2540 - mse: 0.2540 - mae: 0.4038\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch353.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2499 - mse: 0.2499 - mae: 0.3932\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2157 - mse: 0.2157 - mae: 0.3806\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3009 - mse: 0.3009 - mae: 0.4446\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2943 - mse: 0.2943 - mae: 0.4584\n",
      "train set score : mse - 0.24989557266235352 / mae - 0.39315640926361084\n",
      "dev set score : mse - 0.21567033231258392 / mae - 0.38063475489616394\n",
      "test1 set score : mse - 0.3008999824523926 / mae - 0.4445798993110657\n",
      "test2 set score : mse - 0.2943342626094818 / mae - 0.4583868086338043\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 0.2507 - mse: 0.2507 - mae: 0.3903\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch354.h5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2508 - mse: 0.2508 - mae: 0.3891\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2075 - mse: 0.2075 - mae: 0.3707\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3025 - mse: 0.3025 - mae: 0.4438\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2906 - mse: 0.2906 - mae: 0.4529\n",
      "train set score : mse - 0.25082874298095703 / mae - 0.38905563950538635\n",
      "dev set score : mse - 0.20752958953380585 / mae - 0.37073245644569397\n",
      "test1 set score : mse - 0.3024560809135437 / mae - 0.44380655884742737\n",
      "test2 set score : mse - 0.29061397910118103 / mae - 0.4528830647468567\n",
      "2/2 [==============================] - 1s 14ms/step - loss: 0.2496 - mse: 0.2496 - mae: 0.3922\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch355.h5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2536 - mse: 0.2536 - mae: 0.4095\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2469 - mse: 0.2469 - mae: 0.4155\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3011 - mse: 0.3011 - mae: 0.4511\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3104 - mse: 0.3104 - mae: 0.4786\n",
      "train set score : mse - 0.25356343388557434 / mae - 0.4095178544521332\n",
      "dev set score : mse - 0.24692530930042267 / mae - 0.41553443670272827\n",
      "test1 set score : mse - 0.30108797550201416 / mae - 0.4510928690433502\n",
      "test2 set score : mse - 0.3104252219200134 / mae - 0.4786405861377716\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2519 - mse: 0.2519 - mae: 0.4039\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch356.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2514 - mse: 0.2514 - mae: 0.3874\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2046 - mse: 0.2046 - mae: 0.3670\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3031 - mse: 0.3031 - mae: 0.4435\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2894 - mse: 0.2894 - mae: 0.4509\n",
      "train set score : mse - 0.2513773739337921 / mae - 0.3873807191848755\n",
      "dev set score : mse - 0.20456460118293762 / mae - 0.3669991195201874\n",
      "test1 set score : mse - 0.3030712306499481 / mae - 0.44350239634513855\n",
      "test2 set score : mse - 0.289417564868927 / mae - 0.4509338140487671\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2513 - mse: 0.2513 - mae: 0.3876\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch357.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2497 - mse: 0.2497 - mae: 0.3988\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2272 - mse: 0.2272 - mae: 0.3940\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2991 - mse: 0.2991 - mae: 0.4459\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3009 - mse: 0.3009 - mae: 0.4672\n",
      "train set score : mse - 0.24970278143882751 / mae - 0.3987804651260376\n",
      "dev set score : mse - 0.2271897792816162 / mae - 0.39399856328964233\n",
      "test1 set score : mse - 0.2991079092025757 / mae - 0.445926696062088\n",
      "test2 set score : mse - 0.3009127080440521 / mae - 0.4671836495399475\n",
      "2/2 [==============================] - 1s 12ms/step - loss: 0.2497 - mse: 0.2497 - mae: 0.3994\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch358.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2497 - mse: 0.2497 - mae: 0.3992\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2283 - mse: 0.2283 - mae: 0.3952\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2990 - mse: 0.2990 - mae: 0.4461\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3016 - mse: 0.3016 - mae: 0.4680\n",
      "train set score : mse - 0.24969272315502167 / mae - 0.3992304503917694\n",
      "dev set score : mse - 0.22828078269958496 / mae - 0.39518895745277405\n",
      "test1 set score : mse - 0.2989993393421173 / mae - 0.44607362151145935\n",
      "test2 set score : mse - 0.30157148838043213 / mae - 0.4679795205593109\n",
      "2/2 [==============================] - 1s 14ms/step - loss: 0.2494 - mse: 0.2494 - mae: 0.3963\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch359.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2498 - mse: 0.2498 - mae: 0.3900\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2107 - mse: 0.2107 - mae: 0.3747\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3011 - mse: 0.3011 - mae: 0.4436\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2923 - mse: 0.2923 - mae: 0.4554\n",
      "train set score : mse - 0.24981240928173065 / mae - 0.39003705978393555\n",
      "dev set score : mse - 0.21070772409439087 / mae - 0.3746793270111084\n",
      "test1 set score : mse - 0.3011438846588135 / mae - 0.443631649017334\n",
      "test2 set score : mse - 0.2923252284526825 / mae - 0.4553968608379364\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2511 - mse: 0.2511 - mae: 0.3964\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch360.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2491 - mse: 0.2491 - mae: 0.3938\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2185 - mse: 0.2185 - mae: 0.3840\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2998 - mse: 0.2998 - mae: 0.4445\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2960 - mse: 0.2960 - mae: 0.4607\n",
      "train set score : mse - 0.2490808367729187 / mae - 0.39380672574043274\n",
      "dev set score : mse - 0.21851389110088348 / mae - 0.3839656710624695\n",
      "test1 set score : mse - 0.2998451590538025 / mae - 0.44447630643844604\n",
      "test2 set score : mse - 0.2960248589515686 / mae - 0.4606862962245941\n",
      "2/2 [==============================] - 1s 11ms/step - loss: 0.2506 - mse: 0.2506 - mae: 0.3978\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch361.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2505 - mse: 0.2505 - mae: 0.3874\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2063 - mse: 0.2063 - mae: 0.3690\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3024 - mse: 0.3024 - mae: 0.4433\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2903 - mse: 0.2903 - mae: 0.4520\n",
      "train set score : mse - 0.25052717328071594 / mae - 0.3873884081840515\n",
      "dev set score : mse - 0.20634891092777252 / mae - 0.3690130412578583\n",
      "test1 set score : mse - 0.30243057012557983 / mae - 0.4433375298976898\n",
      "test2 set score : mse - 0.29030025005340576 / mae - 0.45203468203544617\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 0.2522 - mse: 0.2522 - mae: 0.3859\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch362.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2494 - mse: 0.2494 - mae: 0.3991\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2294 - mse: 0.2294 - mae: 0.3963\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2992 - mse: 0.2992 - mae: 0.4463\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3014 - mse: 0.3014 - mae: 0.4678\n",
      "train set score : mse - 0.24939924478530884 / mae - 0.3990977704524994\n",
      "dev set score : mse - 0.2293507307767868 / mae - 0.39626961946487427\n",
      "test1 set score : mse - 0.2992337942123413 / mae - 0.44634488224983215\n",
      "test2 set score : mse - 0.30144575238227844 / mae - 0.4678186774253845\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2515 - mse: 0.2515 - mae: 0.4046\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch363.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2489 - mse: 0.2489 - mae: 0.3963\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2240 - mse: 0.2240 - mae: 0.3903\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2992 - mse: 0.2992 - mae: 0.4452\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2989 - mse: 0.2989 - mae: 0.4645\n",
      "train set score : mse - 0.24885863065719604 / mae - 0.39626482129096985\n",
      "dev set score : mse - 0.22401879727840424 / mae - 0.3902902901172638\n",
      "test1 set score : mse - 0.2992253005504608 / mae - 0.4452105164527893\n",
      "test2 set score : mse - 0.29889029264450073 / mae - 0.4645054042339325\n",
      "2/2 [==============================] - 1s 12ms/step - loss: 0.2499 - mse: 0.2499 - mae: 0.3913\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch364.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2504 - mse: 0.2504 - mae: 0.3867\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2054 - mse: 0.2054 - mae: 0.3680\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3025 - mse: 0.3025 - mae: 0.4432\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2897 - mse: 0.2897 - mae: 0.4514\n",
      "train set score : mse - 0.25043368339538574 / mae - 0.38672691583633423\n",
      "dev set score : mse - 0.2054430991411209 / mae - 0.368036687374115\n",
      "test1 set score : mse - 0.3025260865688324 / mae - 0.44322991371154785\n",
      "test2 set score : mse - 0.2897297739982605 / mae - 0.45135611295700073\n",
      "2/2 [==============================] - 1s 18ms/step - loss: 0.2491 - mse: 0.2491 - mae: 0.3911\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch365.h5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2521 - mse: 0.2521 - mae: 0.4076\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2459 - mse: 0.2459 - mae: 0.4144\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3002 - mse: 0.3002 - mae: 0.4502\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3101 - mse: 0.3101 - mae: 0.4781\n",
      "train set score : mse - 0.25205928087234497 / mae - 0.4075603783130646\n",
      "dev set score : mse - 0.24587738513946533 / mae - 0.41438791155815125\n",
      "test1 set score : mse - 0.30023306608200073 / mae - 0.45020562410354614\n",
      "test2 set score : mse - 0.3101068437099457 / mae - 0.47814106941223145\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 0.2509 - mse: 0.2509 - mae: 0.4053\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch366.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2527 - mse: 0.2527 - mae: 0.3834\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.1991 - mse: 0.1991 - mae: 0.3600\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3048 - mse: 0.3048 - mae: 0.4430\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2873 - mse: 0.2873 - mae: 0.4470\n",
      "train set score : mse - 0.25271567702293396 / mae - 0.38344091176986694\n",
      "dev set score : mse - 0.19907169044017792 / mae - 0.3599868714809418\n",
      "test1 set score : mse - 0.30477026104927063 / mae - 0.4430271089076996\n",
      "test2 set score : mse - 0.2873440980911255 / mae - 0.4470469057559967\n",
      "2/2 [==============================] - 1s 12ms/step - loss: 0.2534 - mse: 0.2534 - mae: 0.3828\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch367.h5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2487 - mse: 0.2487 - mae: 0.3974\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2273 - mse: 0.2273 - mae: 0.3940\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2986 - mse: 0.2986 - mae: 0.4455\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3010 - mse: 0.3010 - mae: 0.4672\n",
      "train set score : mse - 0.24865654110908508 / mae - 0.39737820625305176\n",
      "dev set score : mse - 0.2272678166627884 / mae - 0.3939860463142395\n",
      "test1 set score : mse - 0.29857999086380005 / mae - 0.4454984664916992\n",
      "test2 set score : mse - 0.3010132908821106 / mae - 0.46719539165496826\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2511 - mse: 0.2511 - mae: 0.4040\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch368.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2489 - mse: 0.2489 - mae: 0.3990\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2306 - mse: 0.2306 - mae: 0.3977\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2984 - mse: 0.2984 - mae: 0.4461\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3027 - mse: 0.3027 - mae: 0.4694\n",
      "train set score : mse - 0.24887216091156006 / mae - 0.399021178483963\n",
      "dev set score : mse - 0.2305750548839569 / mae - 0.39769911766052246\n",
      "test1 set score : mse - 0.2984194755554199 / mae - 0.4461074769496918\n",
      "test2 set score : mse - 0.3026903569698334 / mae - 0.4693814516067505\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2499 - mse: 0.2499 - mae: 0.3929\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch369.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2507 - mse: 0.2507 - mae: 0.3856\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2038 - mse: 0.2038 - mae: 0.3661\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3021 - mse: 0.3021 - mae: 0.4426\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2896 - mse: 0.2896 - mae: 0.4511\n",
      "train set score : mse - 0.25069522857666016 / mae - 0.38557368516921997\n",
      "dev set score : mse - 0.20377537608146667 / mae - 0.36605292558670044\n",
      "test1 set score : mse - 0.30211612582206726 / mae - 0.442646324634552\n",
      "test2 set score : mse - 0.2896190583705902 / mae - 0.45106950402259827\n",
      "2/2 [==============================] - 1s 13ms/step - loss: 0.2541 - mse: 0.2541 - mae: 0.3988\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch370.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2487 - mse: 0.2487 - mae: 0.3991\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2308 - mse: 0.2308 - mae: 0.3981\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2982 - mse: 0.2982 - mae: 0.4461\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3027 - mse: 0.3027 - mae: 0.4696\n",
      "train set score : mse - 0.2487270087003708 / mae - 0.39913609623908997\n",
      "dev set score : mse - 0.23080796003341675 / mae - 0.398099809885025\n",
      "test1 set score : mse - 0.2981901466846466 / mae - 0.4460947513580322\n",
      "test2 set score : mse - 0.3027294874191284 / mae - 0.4696260094642639\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2482 - mse: 0.2482 - mae: 0.3941\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch371.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2504 - mse: 0.2504 - mae: 0.3857\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2043 - mse: 0.2043 - mae: 0.3667\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3017 - mse: 0.3017 - mae: 0.4425\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2899 - mse: 0.2899 - mae: 0.4516\n",
      "train set score : mse - 0.2504099905490875 / mae - 0.3857281804084778\n",
      "dev set score : mse - 0.2042711228132248 / mae - 0.3667239546775818\n",
      "test1 set score : mse - 0.30168163776397705 / mae - 0.4425312578678131\n",
      "test2 set score : mse - 0.28989553451538086 / mae - 0.45160144567489624\n",
      "2/2 [==============================] - 1s 14ms/step - loss: 0.2507 - mse: 0.2507 - mae: 0.3925\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch372.h5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2487 - mse: 0.2487 - mae: 0.3995\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2318 - mse: 0.2318 - mae: 0.3992\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2982 - mse: 0.2982 - mae: 0.4463\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3029 - mse: 0.3029 - mae: 0.4700\n",
      "train set score : mse - 0.2486666887998581 / mae - 0.39946848154067993\n",
      "dev set score : mse - 0.23176907002925873 / mae - 0.39921367168426514\n",
      "test1 set score : mse - 0.29824548959732056 / mae - 0.44633007049560547\n",
      "test2 set score : mse - 0.30292266607284546 / mae - 0.46996334195137024\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2483 - mse: 0.2483 - mae: 0.3968\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch373.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2486 - mse: 0.2486 - mae: 0.3889\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2107 - mse: 0.2107 - mae: 0.3749\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2999 - mse: 0.2999 - mae: 0.4428\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2926 - mse: 0.2926 - mae: 0.4561\n",
      "train set score : mse - 0.2486283928155899 / mae - 0.388856440782547\n",
      "dev set score : mse - 0.2106902152299881 / mae - 0.3748656213283539\n",
      "test1 set score : mse - 0.2998709976673126 / mae - 0.4428471326828003\n",
      "test2 set score : mse - 0.2925868630409241 / mae - 0.45605453848838806\n",
      "2/2 [==============================] - 1s 14ms/step - loss: 0.2484 - mse: 0.2484 - mae: 0.3894\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch374.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2481 - mse: 0.2481 - mae: 0.3975\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2284 - mse: 0.2284 - mae: 0.3955\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2984 - mse: 0.2984 - mae: 0.4457\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3008 - mse: 0.3008 - mae: 0.4674\n",
      "train set score : mse - 0.2481357604265213 / mae - 0.3975037634372711\n",
      "dev set score : mse - 0.2284233421087265 / mae - 0.3954773545265198\n",
      "test1 set score : mse - 0.2984144985675812 / mae - 0.44571539759635925\n",
      "test2 set score : mse - 0.3008095920085907 / mae - 0.4673845171928406\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2486 - mse: 0.2486 - mae: 0.3993\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch375.h5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2477 - mse: 0.2477 - mae: 0.3917\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2170 - mse: 0.2170 - mae: 0.3824\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2991 - mse: 0.2991 - mae: 0.4437\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2950 - mse: 0.2950 - mae: 0.4597\n",
      "train set score : mse - 0.24773727357387543 / mae - 0.39167898893356323\n",
      "dev set score : mse - 0.21698719263076782 / mae - 0.382445752620697\n",
      "test1 set score : mse - 0.2991475760936737 / mae - 0.44368115067481995\n",
      "test2 set score : mse - 0.29498252272605896 / mae - 0.45968183875083923\n",
      "2/2 [==============================] - 1s 14ms/step - loss: 0.2487 - mse: 0.2487 - mae: 0.3891\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch376.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2476 - mse: 0.2476 - mae: 0.3918\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2178 - mse: 0.2178 - mae: 0.3833\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2993 - mse: 0.2993 - mae: 0.4439\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2950 - mse: 0.2950 - mae: 0.4597\n",
      "train set score : mse - 0.24759788811206818 / mae - 0.3918275535106659\n",
      "dev set score : mse - 0.2177513986825943 / mae - 0.38329946994781494\n",
      "test1 set score : mse - 0.2992747724056244 / mae - 0.44385984539985657\n",
      "test2 set score : mse - 0.29498937726020813 / mae - 0.45972830057144165\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2481 - mse: 0.2481 - mae: 0.3957\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch377.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2479 - mse: 0.2479 - mae: 0.3972\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2291 - mse: 0.2291 - mae: 0.3960\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2988 - mse: 0.2988 - mae: 0.4459\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3005 - mse: 0.3005 - mae: 0.4668\n",
      "train set score : mse - 0.24791313707828522 / mae - 0.39721521735191345\n",
      "dev set score : mse - 0.22905504703521729 / mae - 0.3960236608982086\n",
      "test1 set score : mse - 0.2988116145133972 / mae - 0.44593510031700134\n",
      "test2 set score : mse - 0.30046001076698303 / mae - 0.466840922832489\n",
      "2/2 [==============================] - 1s 14ms/step - loss: 0.2474 - mse: 0.2474 - mae: 0.3946\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch378.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2491 - mse: 0.2491 - mae: 0.3854\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2057 - mse: 0.2057 - mae: 0.3685\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3024 - mse: 0.3024 - mae: 0.4431\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2888 - mse: 0.2888 - mae: 0.4505\n",
      "train set score : mse - 0.24907195568084717 / mae - 0.38541704416275024\n",
      "dev set score : mse - 0.20568859577178955 / mae - 0.3684552013874054\n",
      "test1 set score : mse - 0.30235540866851807 / mae - 0.4430529773235321\n",
      "test2 set score : mse - 0.2888280153274536 / mae - 0.4504975378513336\n",
      "2/2 [==============================] - 1s 12ms/step - loss: 0.2485 - mse: 0.2485 - mae: 0.3880\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch379.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2477 - mse: 0.2477 - mae: 0.3967\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2291 - mse: 0.2291 - mae: 0.3959\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2994 - mse: 0.2994 - mae: 0.4462\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2996 - mse: 0.2996 - mae: 0.4657\n",
      "train set score : mse - 0.24774879217147827 / mae - 0.3967123329639435\n",
      "dev set score : mse - 0.22908657789230347 / mae - 0.39591214060783386\n",
      "test1 set score : mse - 0.29943186044692993 / mae - 0.4461696445941925\n",
      "test2 set score : mse - 0.29956841468811035 / mae - 0.4656652808189392\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2477 - mse: 0.2477 - mae: 0.3954\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch380.h5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2472 - mse: 0.2472 - mae: 0.3906\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2177 - mse: 0.2177 - mae: 0.3829\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3006 - mse: 0.3006 - mae: 0.4443\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2933 - mse: 0.2933 - mae: 0.4573\n",
      "train set score : mse - 0.24720411002635956 / mae - 0.39064133167266846\n",
      "dev set score : mse - 0.21765007078647614 / mae - 0.38285690546035767\n",
      "test1 set score : mse - 0.3006015717983246 / mae - 0.4442620277404785\n",
      "test2 set score : mse - 0.2932906448841095 / mae - 0.4573230445384979\n",
      "2/2 [==============================] - 1s 15ms/step - loss: 0.2484 - mse: 0.2484 - mae: 0.3942\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch381.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2477 - mse: 0.2477 - mae: 0.3872\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2106 - mse: 0.2106 - mae: 0.3744\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3018 - mse: 0.3018 - mae: 0.4435\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2903 - mse: 0.2903 - mae: 0.4528\n",
      "train set score : mse - 0.24772655963897705 / mae - 0.3871556520462036\n",
      "dev set score : mse - 0.21063032746315002 / mae - 0.37442970275878906\n",
      "test1 set score : mse - 0.301764577627182 / mae - 0.44349029660224915\n",
      "test2 set score : mse - 0.2902543842792511 / mae - 0.45277029275894165\n",
      "2/2 [==============================] - 1s 14ms/step - loss: 0.2499 - mse: 0.2499 - mae: 0.3855\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch382.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2475 - mse: 0.2475 - mae: 0.3963\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2296 - mse: 0.2296 - mae: 0.3964\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2996 - mse: 0.2996 - mae: 0.4462\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2998 - mse: 0.2998 - mae: 0.4657\n",
      "train set score : mse - 0.24747397005558014 / mae - 0.39628732204437256\n",
      "dev set score : mse - 0.22964228689670563 / mae - 0.396380752325058\n",
      "test1 set score : mse - 0.2995748817920685 / mae - 0.4462266266345978\n",
      "test2 set score : mse - 0.2997840940952301 / mae - 0.46573400497436523\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 0.2492 - mse: 0.2492 - mae: 0.4014\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch383.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2469 - mse: 0.2469 - mae: 0.3923\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2217 - mse: 0.2217 - mae: 0.3876\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2997 - mse: 0.2997 - mae: 0.4446\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2961 - mse: 0.2961 - mae: 0.4610\n",
      "train set score : mse - 0.24687379598617554 / mae - 0.39227139949798584\n",
      "dev set score : mse - 0.22171126306056976 / mae - 0.387550413608551\n",
      "test1 set score : mse - 0.2996513545513153 / mae - 0.44460147619247437\n",
      "test2 set score : mse - 0.2960655987262726 / mae - 0.46098825335502625\n",
      "2/2 [==============================] - 1s 16ms/step - loss: 0.2482 - mse: 0.2482 - mae: 0.3867\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch384.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2480 - mse: 0.2480 - mae: 0.3858\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2088 - mse: 0.2088 - mae: 0.3722\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.3012 - mse: 0.3012 - mae: 0.4428\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2908 - mse: 0.2908 - mae: 0.4531\n",
      "train set score : mse - 0.24798204004764557 / mae - 0.3858312666416168\n",
      "dev set score : mse - 0.20879800617694855 / mae - 0.3721533715724945\n",
      "test1 set score : mse - 0.30124393105506897 / mae - 0.44280916452407837\n",
      "test2 set score : mse - 0.29082027077674866 / mae - 0.453076034784317\n",
      "2/2 [==============================] - 1s 13ms/step - loss: 0.2478 - mse: 0.2478 - mae: 0.3915\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch385.h5\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2492 - mse: 0.2492 - mae: 0.4031\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2427 - mse: 0.2427 - mae: 0.4108\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2995 - mse: 0.2995 - mae: 0.4488\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3078 - mse: 0.3078 - mae: 0.4753\n",
      "train set score : mse - 0.2492000162601471 / mae - 0.40306779742240906\n",
      "dev set score : mse - 0.24267280101776123 / mae - 0.4108264744281769\n",
      "test1 set score : mse - 0.2995183765888214 / mae - 0.4487774670124054\n",
      "test2 set score : mse - 0.30775246024131775 / mae - 0.47530877590179443\n",
      "2/2 [==============================] - 1s 14ms/step - loss: 0.2476 - mse: 0.2476 - mae: 0.3970\n",
      "\n",
      "Epoch 00001: saving model to ./models/hybrid_LSTM\\epoch386.h5\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2495 - mse: 0.2495 - mae: 0.3831\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2033 - mse: 0.2033 - mae: 0.3653\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3024 - mse: 0.3024 - mae: 0.4424\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 0.2889 - mse: 0.2889 - mae: 0.4499\n",
      "train set score : mse - 0.24949464201927185 / mae - 0.38310277462005615\n",
      "dev set score : mse - 0.20325973629951477 / mae - 0.3653428852558136\n",
      "test1 set score : mse - 0.30240121483802795 / mae - 0.4423568844795227\n",
      "test2 set score : mse - 0.2889188826084137 / mae - 0.4498859643936157\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Activation\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "train_X= pd.read_csv('./my_data/train_dev_test/after_arima/train_X.csv')\n",
    "print('loaded train_X')\n",
    "dev_X = pd.read_csv('./my_data/train_dev_test/after_arima/dev_X.csv')\n",
    "print('loaded dev_X')\n",
    "test1_X = pd.read_csv('./my_data/train_dev_test/after_arima/test1_X.csv')\n",
    "print('loaded test1_X')\n",
    "test2_X = pd.read_csv('./my_data/train_dev_test/after_arima/test2_X.csv')\n",
    "print('loaded test2_X')\n",
    "train_Y = pd.read_csv('./my_data/train_dev_test/after_arima/train_Y.csv')\n",
    "print('loaded train_Y')\n",
    "dev_Y = pd.read_csv('./my_data/train_dev_test/after_arima/dev_Y.csv')\n",
    "print('loaded dev_Y')\n",
    "test1_Y = pd.read_csv('./my_data/train_dev_test/after_arima/test1_Y.csv')\n",
    "print('loaded test1_Y')\n",
    "test2_Y = pd.read_csv('./my_data/train_dev_test/after_arima/test2_Y.csv')\n",
    "print('loaded test2_Y')\n",
    "train_X = train_X.loc[:, ~train_X.columns.str.contains('^Unnamed')]\n",
    "dev_X = dev_X.loc[:, ~dev_X.columns.str.contains('^Unnamed')]\n",
    "test1_X = test1_X.loc[:, ~test1_X.columns.str.contains('^Unnamed')]\n",
    "test2_X = test2_X.loc[:, ~test2_X.columns.str.contains('^Unnamed')]\n",
    "train_Y = train_Y.loc[:, ~train_Y.columns.str.contains('^Unnamed')]\n",
    "dev_Y = dev_Y.loc[:, ~dev_Y.columns.str.contains('^Unnamed')]\n",
    "test1_Y = test1_Y.loc[:, ~test1_Y.columns.str.contains('^Unnamed')]\n",
    "test2_Y = test2_Y.loc[:, ~test2_Y.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# data sampling\n",
    "STEP = 20\n",
    "#num_list = [STEP*i for i in range(int(1117500/STEP))]\n",
    "\n",
    "_train_X = np.asarray(train_X).reshape((int(950), 20, 1))\n",
    "_dev_X = np.asarray(dev_X).reshape((int(950), 20, 1))\n",
    "_test1_X = np.asarray(test1_X).reshape((int(950), 20, 1))\n",
    "_test2_X = np.asarray(test2_X).reshape((int(950), 20, 1))\n",
    "\n",
    "_train_Y = np.asarray(train_Y).reshape(int(950), 1)\n",
    "_dev_Y = np.asarray(dev_Y).reshape(int(950), 1)\n",
    "_test1_Y = np.asarray(test1_Y).reshape(int(950), 1)\n",
    "_test2_Y = np.asarray(test2_Y).reshape(int(950), 1)\n",
    "\n",
    "\n",
    "class Double_Tanh(Activation):\n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(Double_Tanh, self).__init__(activation, **kwargs)\n",
    "        self.__name__ = 'double_tanh'\n",
    "\n",
    "def double_tanh(x):\n",
    "    return (2*K.tanh(x))\n",
    "\n",
    "get_custom_objects().update({'double_tanh':Double_Tanh(double_tanh)})\n",
    "\n",
    "\n",
    "# Model Generation\n",
    "model = Sequential()\n",
    "#check https://machinelearningmastery.com/use-weight-regularization-lstm-networks-time-series-forecasting/\n",
    "model.add(LSTM(25, input_shape=(20,1), dropout=0.0, kernel_regularizer=l1_l2(0.00,0.00), bias_regularizer=l1_l2(0.00,0.00)))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(double_tanh))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae'])\n",
    "#, kernel_regularizer=l1_l2(0,0.1), bias_regularizer=l1_l2(0,0.1),\n",
    "\n",
    "print(model.metrics_names)\n",
    "\n",
    "\n",
    "# Fitting the Model\n",
    "model_scores = {}\n",
    "Reg = False\n",
    "d = 'hybrid_LSTM'\n",
    "\n",
    "if Reg :\n",
    "    d += '_with_reg'\n",
    "\n",
    "epoch_num=1\n",
    "for _ in range(124):\n",
    "\n",
    "    # train the model\n",
    "    dir = './models/'+d\n",
    "    file_list = os.listdir(dir)\n",
    "    if len(file_list) != 0 :\n",
    "        epoch_num = len(file_list) + 1\n",
    "        recent_model_name = 'epoch'+str(epoch_num-1)+'.h5'\n",
    "        filepath = './models/' + d + '/' + recent_model_name\n",
    "        model = load_model(filepath,custom_objects={'double_tanh': double_tanh})\n",
    "\n",
    "    filepath = './models/' + d + '/epoch'+str(epoch_num)+'.h5'\n",
    "\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "    if len(callbacks_list) == 0:\n",
    "        model.fit(_train_X, _train_Y, epochs=1, batch_size=500, shuffle=True)\n",
    "    else:\n",
    "        model.fit(_train_X, _train_Y, epochs=1, batch_size=500, shuffle=True, callbacks=callbacks_list)\n",
    "\n",
    "    # test the model\n",
    "    score_train = model.evaluate(_train_X, _train_Y)\n",
    "    score_dev = model.evaluate(_dev_X, _dev_Y)\n",
    "    score_test1 = model.evaluate(_test1_X, _test1_Y)\n",
    "    score_test2 = model.evaluate(_test2_X, _test2_Y)\n",
    "\n",
    "    print('train set score : mse - ' + str(score_train[1]) +' / mae - ' + str(score_train[2]))\n",
    "    print('dev set score : mse - ' + str(score_dev[1]) +' / mae - ' + str(score_dev[2]))\n",
    "    print('test1 set score : mse - ' + str(score_test1[1]) +' / mae - ' + str(score_test1[2]))\n",
    "    print('test2 set score : mse - ' + str(score_test2[1]) +' / mae - ' + str(score_test2[2]))\n",
    "#.history['mean_squared_error'][0]\n",
    "    # get former score data\n",
    "    df = pd.read_csv(\"./models/\"+d+\".csv\")\n",
    "    train_mse = list(df['TRAIN_MSE'])\n",
    "    dev_mse = list(df['DEV_MSE'])\n",
    "    test1_mse = list(df['TEST1_MSE'])\n",
    "    test2_mse = list(df['TEST2_MSE'])\n",
    "\n",
    "    train_mae = list(df['TRAIN_MAE'])\n",
    "    dev_mae = list(df['DEV_MAE'])\n",
    "    test1_mae = list(df['TEST1_MAE'])\n",
    "    test2_mae = list(df['TEST2_MAE'])\n",
    "\n",
    "    # append new data\n",
    "    train_mse.append(score_train[1])\n",
    "    dev_mse.append(score_dev[1])\n",
    "    test1_mse.append(score_test1[1])\n",
    "    test2_mse.append(score_test2[1])\n",
    "\n",
    "    train_mae.append(score_train[2])\n",
    "    dev_mae.append(score_dev[2])\n",
    "    test1_mae.append(score_test1[2])\n",
    "    test2_mae.append(score_test2[2])\n",
    "\n",
    "    # organize newly created score dataset\n",
    "    model_scores['TRAIN_MSE'] = train_mse\n",
    "    model_scores['DEV_MSE'] = dev_mse\n",
    "    model_scores['TEST1_MSE'] = test1_mse\n",
    "    model_scores['TEST2_MSE'] = test2_mse\n",
    "\n",
    "    model_scores['TRAIN_MAE'] = train_mae\n",
    "    model_scores['DEV_MAE'] = dev_mae\n",
    "    model_scores['TEST1_MAE'] = test1_mae\n",
    "    model_scores['TEST2_MAE'] = test2_mae\n",
    "\n",
    "    # save newly created score dataset\n",
    "    model_scores_df = pd.DataFrame(model_scores)\n",
    "    model_scores_df.to_csv(\"./models/\"+d+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_scores_df[['TRAIN_MSE', 'TEST1_MSE', 'TEST2_MSE']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_scores_df[['TRAIN_MAE',  'TEST1_MAE', 'TEST2_MAE']].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
